{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Science Eng Methods and Tools, Lecture 12 Day 2</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 1 April 2020</div>\n",
    "\n",
    "# Caterpillar brain\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/caterpillar.jpg width = 400 />\n",
    "</center>\n",
    "\n",
    "So we drew a small brain last time, so now we're going to *design* one! Today is April's fool day, so we're all caterpillars! How many feet do we have? 16!\n",
    "\n",
    ">Hey, no lauging, *you* try coordinating 16 feet!\n",
    "\n",
    "Now assume we sense feedback from our 16 feet, and want to decide whether it means we should move *forward* or *backward*. From *experience* we learn that based on the combined input of our feet-sensory neurons, sometimes we should go forward and sometimes backward, and we want to *learn* from that experience because if we don't decide right, we *face-plant*.\n",
    "\n",
    "So we pop open our caterpillar laptop and fire up Excel, and look at our following spreadsheet:\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/excel.png width = 400 />\n",
    "</center>\n",
    "\n",
    "It has 17 **features** (columns): The first 16 that correspond to each of our 16 feet, and the last one (the label) says whether, based on the specific input from our feet, we *should* go forward, or *backward*. We wrote our walking history down carefully in our Excel spreadsheet as we are learning how to walk and are still very unsure. But we know how to type 0 and 1 in an Excel spreadheet pretty well! \n",
    "\n",
    "Let's assume that we sense only binary input from each one of our feet (i.e. foot touches ground or does not touch ground), and that 1 means go forward and 0 means go backward, and we'd like to *learn* that.\n",
    "\n",
    "So, how many *independent variables*?\n",
    "\n",
    "How many *dependent variables*?\n",
    "\n",
    "How many **observations** (rows)? Well, we don't know that yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "In other words, the goal is to predict one of two states (forward or backward), using a collection of features (feet sensory input) which are all binary. This is called **supervised learning** because we have written down what we *should do* (the label), and we want to train our brain to predict the label based on the 16 sensory features. \n",
    "\n",
    "This is also called **discriminative learning**, rather than **generative learning**, because we do not wish to regenerate the initial signal (feet sensory input), but rather we want to predict a 0 (move backwards) or 1 (move forward) in order to avoid a face-plant! So we want to *discriminate* between 0 and 1.\n",
    "\n",
    "Our graph edges so far have been equal-weighted. But with brains, our edges acquire weights between nodes. It's a bit similar to facebook friends graphs. Our facebook friends are simiarly weighted, but in reality we like some friends a lot more than others!\n",
    "\n",
    "The prediction model in our caterpillar brain is simple: We assign weights to each feature (foot sensory input). To predict movement forward or backward based on an observation, we check all features that are *active* (foot is on the ground, or = 1) and sum up the weights assigned to these features. If the total is *above* a certain threshold, the result is interpreted as *move forward*, otherwise it’s *move backwards*. \n",
    "\n",
    "So our brain is a graph and we initialize edge weights $w_1 = w_2 = \\cdots = w_n = 1$.\n",
    "\n",
    "Then we iterate on each observation of sensory input from all of our feet, consisting of a vector of dimension $n$: $ = [x_1, x_2, \\cdots, x_n]$, where $x_i$ corresponds to foot *i* sensory input.\n",
    "\n",
    "How do we learn? With a **loop**! We loop through our foot-sensory observations (rows) and predict (for each iteration, or **epoch**), using some kind of linear algebra linear map transformation on our neural weights if our brain should output 1 *(go forward)*, or 0 *(go backward)*.\n",
    "\n",
    "Then, we look up the label corresponding to that foot-sensory observation (we wrote down whether, based on a specific foot-sensory observation for each one of our feet, we should go forward or backward), and we update the weights **only if we make a mistake**:\n",
    "- **False-positive** error (we predicted 0, go backwards, whereas the label is 1 or go forward): Then for each $x_i == 1$, we set $w_i = 2*w_i$.\n",
    "- **False-negative** error (we predicted 1, go forward, whereas the label is 0 or go backward): Then for each $x_i == 1$, we set $wi = wi/2$.\n",
    "\n",
    "Here is the *machine learning* interpretation of the logic above:\n",
    "If our caterpillar brain predicts walk forward but should predict go backward, it is **over-shooting**, so weights that were used in that prediction (i.e. the weights attached to active features) should be reduced.\n",
    "Conversely, if the prediction is walk backward but the correct result should be walk forward, the active features are not used enough to reach the threshold, so weights should be bumped up.\n",
    "\n",
    "Our goal is to minimize the number of face-plants! When we're down to the minimum, we say we have **converged** in our learning, and we can now walk with very few face-plants! We are a *proud* little caterpillar.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/happy-caterpillar.gif width = 400 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caterpillar algorithm:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "initialize weights in our little caterpillar brain\n",
    "loop until done with learning\n",
    "  for each training item (observation of foot sensory input)\n",
    "    compute move (Y)\n",
    "    if move is correct do nothing\n",
    "    else if move is incorrect\n",
    "      if computed Y is too high\n",
    "        divide all relevant weights by 2.0\n",
    "      else if computed Y is too small\n",
    "        multiply all relevant weights by 2.0\n",
    "  end for\n",
    "end loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "class Caterpillar:\n",
    "    numInput = 0\n",
    "    weights = []\n",
    "    threshold = 0.0\n",
    "    alpha = 0.0\n",
    "    \n",
    "    def __init__(self, numInput, rndSeed):\n",
    "        self.numInput = numInput\n",
    "        self.weights = [0] *numInput\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] = numInput / 2.0\n",
    "        self.threshold = 1.0 * numInput\n",
    "        self.alpha = 2.0\n",
    "        random.seed( rndSeed )\n",
    "        \n",
    "    # int[] xValues\n",
    "    def ComputeY(self, xValues):\n",
    "        sum = 0.0\n",
    "        for i in range(numInput):\n",
    "            sum += self.weights[i] * xValues[i]\n",
    "        if sum > self.threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "     \n",
    "    # Fisher-Yates shuffle algorithm int[][] trainData\n",
    "    def ShuffleObservations(self, trainData):\n",
    "        for i in range(len(trainData)):\n",
    "            r = randint(i, len(trainData) - 1)\n",
    "            tmp = []\n",
    "            tmp = trainData[r]\n",
    "            trainData[r] = trainData[i]\n",
    "            trainData[i] = tmp\n",
    "         \n",
    "    # returns double, int[][] trainData\n",
    "    def Accuracy(self, trainData):\n",
    "        numCorrect = 0\n",
    "        numWrong = 0\n",
    "        xValues = [0] *numInput\n",
    "        \n",
    "        for i in range(len(trainData)):\n",
    "            xValues = np.copy(trainData[i])\n",
    "            target = trainData[i][numInput] #last value is target\n",
    "            computed = self.ComputeY(xValues)\n",
    "\n",
    "            if computed == target:\n",
    "                numCorrect += 1\n",
    "            else:\n",
    "                numWrong += 1\n",
    "                \n",
    "        return (numCorrect * 1.0) / (numCorrect + numWrong)\n",
    "    \n",
    "    # returns double[], int[][] trainData\n",
    "    def TrainWeights(self, trainData):\n",
    "        xValues = [] * numInput\n",
    "        self.ShuffleObservations(trainData)\n",
    "        for i in range(len(trainData)):\n",
    "            #  get the inputs\n",
    "            xValues = np.copy(trainData[i])\n",
    "            \n",
    "            #  last value is target\n",
    "            target = trainData[i][numInput] \n",
    "            \n",
    "            computed = self.ComputeY(xValues)\n",
    "\n",
    "            if (computed == 1 and target == 0):\n",
    "                # need to decrease weight:\n",
    "                for j in range(numInput):\n",
    "                    if (xValues[j] == 0): continue\n",
    "                    self.weights[j] = self.weights[j] / self.alpha #demotion\n",
    "            elif (computed == 0 and target == 1):\n",
    "                # need to increase weight:\n",
    "                for j in range(numInput):\n",
    "                    if (xValues[j] == 0): continue\n",
    "                    self.weights[j] = self.weights[j] * self.alpha #promotion\n",
    "\n",
    "        result = [0.0] *numInput # = number weights\n",
    "        result = self.weights\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double[] vector\n",
    "def ShowVector(vector, decimals, valsPerRow, newLine):\n",
    "    frmt = '%.' + str(decimals) + 'f'\n",
    "    for i in range(len(vector)):\n",
    "        if (i % valsPerRow == 0): print(\"\", end='')\n",
    "        print(frmt % vector[i] + \" \", end='')\n",
    "    if (newLine): print(\"\")\n",
    "\n",
    "# int[][] matrix\n",
    "def ShowMatrix(matrix, decimals, numRows, indices):\n",
    "    frmt = '%.' + str(decimals) + 'f'\n",
    "    for i in range(numRows):\n",
    "        if (indices):\n",
    "            print(\"[\" + '%02d' % i + \"]   \", end='')\n",
    "        for j in range(len(matrix[i])):\n",
    "            print(frmt % matrix[i][j] + \" \", end='')\n",
    "        print(\"\")\n",
    "    lastIndex = len(matrix) - 1\n",
    "    if (indices):\n",
    "        print(\"[\" + '%02d' % lastIndex + \"]   \", end='')\n",
    "    for j in range(len(matrix[lastIndex])):\n",
    "        print(frmt % matrix[lastIndex][j] + \" \", end='')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# int[][] data, seed, out int[][] trainData, out int[][] testData\n",
    "def MakeTrainTest(data, pct, seed):\n",
    "    totRows = data.shape[0] #compute number of rows in each result\n",
    "    numTrainRows = int(totRows * pct)\n",
    "    numTestRows = totRows - numTrainRows\n",
    "    #trainData = new int[numTrainRows][]\n",
    "    trainData = np.empty(data.shape)\n",
    "    #testData = new int[numTestRows][]\n",
    "    testData = np.empty(data.shape)\n",
    "    copy = np.empty(data.shape)\n",
    "\n",
    "    # int[][] copy = new int[data.Length][] #  make a copy of data\n",
    "    for i in range(copy.shape[0]):\n",
    "        # by reference to save space\n",
    "        copy[i] = data[i]\n",
    "    for i in range(copy.shape[0]):\n",
    "        # scramble row order of copy\n",
    "        r = randint(i, copy.shape[0] - 1)\n",
    "        tmp = copy[r]\n",
    "        copy[r] = copy[i]\n",
    "        copy[i] = tmp\n",
    "    for i in range(numTrainRows):\n",
    "        # create training\n",
    "        trainData[i] = copy[i]\n",
    "    for i in range(numTestRows):\n",
    "        # create test\n",
    "        testData[i] = copy[i + numTrainRows]\n",
    "        \n",
    "    return trainData, testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is our excel spreadsheeet, already conveniently broken down into a matrix for you!\n",
    "\n",
    "1st column is sensory input from foot 1,\n",
    "2nd column is sensory input from foot 2,\n",
    "3rd column is sensory input from foot 3, \n",
    "etc.\n",
    "\n",
    "All 16 columns are either 1 for foot touches ground or 0 for foot does not touch ground. \n",
    "\n",
    "The last column is what our little caterpillar body *should* do: move forward (1), or backward (0). It's the label!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.empty((100,17))\n",
    "\n",
    "data[0] =  [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1 ] #  last col is dem = 0, rep = 1\n",
    "data[1] =  [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[2] =  [ 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0 ]\n",
    "data[3] =  [ 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0 ]\n",
    "data[4] =  [ 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0 ]\n",
    "data[5] =  [ 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0 ]\n",
    "data[6] =  [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0 ]\n",
    "data[7] =  [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1 ]\n",
    "data[8] =  [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1 ]\n",
    "data[9] =  [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
    "data[10] = [ 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1 ]\n",
    "data[11] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1 ]\n",
    "data[12] = [ 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0 ]\n",
    "data[13] = [ 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0 ]\n",
    "data[14] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1 ]\n",
    "data[15] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1 ]\n",
    "data[16] = [ 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0 ]\n",
    "data[17] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0 ]\n",
    "data[18] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1 ]\n",
    "data[19] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0 ]\n",
    "data[20] = [ 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0 ]\n",
    "data[21] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0 ]\n",
    "data[22] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0 ]\n",
    "data[23] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0 ]\n",
    "data[24] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0 ]\n",
    "data[25] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0 ]\n",
    "data[26] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0 ]\n",
    "data[27] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0 ]\n",
    "data[28] = [ 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1 ]\n",
    "data[29] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0 ]\n",
    "data[30] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[31] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0 ]\n",
    "data[32] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0 ]\n",
    "data[33] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1 ]\n",
    "data[34] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0 ]\n",
    "data[35] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[36] = [ 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1 ]\n",
    "data[37] = [ 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1 ]\n",
    "data[38] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[39] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0 ]\n",
    "data[40] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
    "data[41] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0 ]\n",
    "data[42] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0 ]\n",
    "data[43] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0 ]\n",
    "data[44] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0 ]\n",
    "data[45] = [ 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0 ]\n",
    "data[46] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0 ]\n",
    "data[47] = [ 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
    "data[48] = [ 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0 ]\n",
    "data[49] = [ 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[50] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0 ]\n",
    "data[51] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1 ]\n",
    "data[52] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
    "data[53] = [ 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[54] = [ 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0 ]\n",
    "data[55] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1 ]\n",
    "data[56] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1 ]\n",
    "data[57] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1 ]\n",
    "data[58] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1 ]\n",
    "data[59] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[60] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0 ]\n",
    "data[61] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[62] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
    "data[63] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0 ]\n",
    "data[64] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0 ]\n",
    "data[65] = [ 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1 ]\n",
    "data[66] = [ 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1 ]\n",
    "data[67] = [ 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[68] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0 ]\n",
    "data[69] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0 ]\n",
    "data[70] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0 ]\n",
    "data[71] = [ 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1 ]\n",
    "data[72] = [ 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0 ]\n",
    "data[73] = [ 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1 ]\n",
    "data[74] = [ 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0 ]\n",
    "data[75] = [ 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0 ]\n",
    "data[76] = [ 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0 ]\n",
    "data[77] = [ 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0 ]\n",
    "data[78] = [ 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0 ]\n",
    "data[79] = [ 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[80] = [ 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0 ]\n",
    "data[81] = [ 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0 ]\n",
    "data[82] = [ 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1 ]\n",
    "data[83] = [ 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[84] = [ 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[85] = [ 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0 ]\n",
    "data[86] = [ 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[87] = [ 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1 ]\n",
    "data[88] = [ 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0 ]\n",
    "data[89] = [ 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1 ]\n",
    "data[90] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0 ]\n",
    "data[91] = [ 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0 ]\n",
    "data[92] = [ 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0 ]\n",
    "data[93] = [ 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0 ]\n",
    "data[94] = [ 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0 ]\n",
    "data[95] = [ 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0 ]\n",
    "data[96] = [ 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0 ]\n",
    "data[97] = [ 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0 ]\n",
    "data[98] = [ 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0 ]\n",
    "data[99] = [ 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few lines of all data are:\n",
      "[00]   0 1 0 1 1 1 0 0 0 1 0 1 1 1 0 1 1 \n",
      "[01]   0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 0 1 \n",
      "[02]   0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 \n",
      "[03]   0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 \n",
      "[99]   0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 \n"
     ]
    }
   ],
   "source": [
    "print(\"First few lines of all data are:\")\n",
    "ShowMatrix(data, 0, 4, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly split an 100-observation excel spreadsheet into an 80-item training set to generate our caterpillar model. A 20-item test set is earmarked to evaluate the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into 80% train and 20% test matrices\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting data into 80% train and 20% test matrices\")\n",
    "trainData, testData = MakeTrainTest(data, 0.8, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of training data are:\n",
      "[00]   0 1 0 1 1 1 0 0 0 1 0 1 1 1 0 1 1 \n",
      "[01]   0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 0 1 \n",
      "[02]   0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 \n",
      "[99]   0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 \n"
     ]
    }
   ],
   "source": [
    "print(\"First few rows of training data are:\")\n",
    "ShowMatrix(trainData, 0, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of testing data are:\n",
      "[00]   0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 1 \n",
      "[01]   0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 \n",
      "[02]   1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 \n",
      "[99]   0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n"
     ]
    }
   ],
   "source": [
    "print(\"First few rows of testing data are:\")\n",
    "ShowMatrix(testData, 0, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData = MakeTrainTest(data, 0.8, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training using Winnow algorithm\n",
      "Training complete\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Begin training using Winnow algorithm\")\n",
    "numInput = 16\n",
    "w = Caterpillar(numInput,58) #rndSeed = 0\n",
    "weights = w.TrainWeights(trainData)\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model weights are:\n",
      "0.5000 0.2500 0.1250 8.0000 2.0000 0.0312 2.0000 1.0000 4.0000 2.0000 0.2500 8.0000 8.0000 1.0000 0.1250 0.0625 \n"
     ]
    }
   ],
   "source": [
    "print(\"Final model weights are:\")\n",
    "ShowVector(weights, 4, 8, True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training history for weights:\n",
    "\n",
    "fairly ok results:\n",
    "0.5000 0.1250 0.0625 16.0000 2.0000 0.2500 1.0000 1.0000 2.0000 2.0000 0.5000 8.0000 1.0000 2.0000 0.2500 0.5000 \n",
    "0.5000 0.2500 0.1250 8.0000 2.0000 0.1250 2.0000 1.0000 4.0000 2.0000 0.2500 4.0000 2.0000 2.0000 1.0000 0.5000\n",
    "\n",
    "perfect results:\n",
    "0.5000 0.2500 0.1250 8.0000 2.0000 0.5000 2.0000 1.0000 2.0000 2.0000 0.5000 4.0000 4.0000 2.0000 0.2500 0.5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy on training data = 1.0\n",
      "Prediction accuracy on test data = 0.48\n"
     ]
    }
   ],
   "source": [
    "trainAcc = w.Accuracy(trainData)\n",
    "testAcc = w.Accuracy(testData)\n",
    "\n",
    "print(\"Prediction accuracy on training data = \" + str(trainAcc))\n",
    "print(\"Prediction accuracy on test data = \" + str(testAcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should shoot for a training data accuracy above 90%, and a test data accuracy above 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting move when all our feet touch ground: forward!\n",
      "Predicting move when no feet touch ground: move backward!\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting move when all our feet touch ground: \", end='')\n",
    "yays = [ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ]\n",
    "predicted = w.ComputeY(yays)\n",
    "if predicted == 0:\n",
    "    print(\"move backward!\")\n",
    "else:\n",
    "    print(\"forward!\")\n",
    "\n",
    "print(\"Predicting move when no feet touch ground: \", end='')\n",
    "nays = [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
    "predicted2 = w.ComputeY(nays)\n",
    "if predicted2 == 0:\n",
    "    print(\"move backward!\")\n",
    "else:\n",
    "    print(\"forward!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign weights based on each observation of feet sensory input. Some sensory inputs (for some reason) are going to be very discriminative about movement, others much less so. The discriminative ones acquire higher weights. The *frivolous* ones much less.\n",
    "\n",
    "The algorithm uses only incorrect information. Correct information (correct guess of a label) yields a `nop`. So the algorithm essentially drives the weights of irrelevant predictors to 0, *winnowing them out*. This makes our winnowing classification effective in situations where many of the predictor variables are irrelevant (frivolous). It's a good way to figure out the important (discriminative) factors. \n",
    "\n",
    "It is *unclear* how long to train for. We iterate just once through the training data. An alternative would be to \n",
    "Iterate multiple times through the training data, stopping after a fixed number of iterations, or when some desired accuracy has been reached.\n",
    "\n",
    "Success? Believe it or not, **Machine Learning** algorithms are not much different in methodology. Their modeling power is higher due to non-linearities we're going to discuss. But the methodology is very similar:\n",
    "\n",
    "- Partition data set into 80% observations and 20% test\n",
    "- Train model with feature observations in order to refine weights (synapse strength)\n",
    "\n",
    "Once our weights are determined, we can reuse them for any other observation with similar features. Most of the Machine Learning research in the last 20 years was about how to update the weights and what kind of non-linear function to use as a neural transfer function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: Single Proton Emission Computed Tomography data\n",
    "\n",
    "You know what? I betcha that little caterpillar brain can rival [IBM's Watson](https://www.ibm.com/watson?p1=Search&p4=p50370936620&p5=e&cm_mmc=Search_Google-_-1S_1S-_-WW_NA-_-ibm%20watson_e&cm_mmca7=71700000060771776&cm_mmca8=aud-309367918490:kwd-2846208261&cm_mmca9=Cj0KCQjw1Iv0BRDaARIsAGTWD1uESxxDiNteKuSnd_PrZTJjGvVJKDeqHT5GA5PkomcD6rhlYa8-he0aAjdoEALw_wcB&cm_mmca10=406603549677&cm_mmca11=e&gclid=Cj0KCQjw1Iv0BRDaARIsAGTWD1uESxxDiNteKuSnd_PrZTJjGvVJKDeqHT5GA5PkomcD6rhlYa8-he0aAjdoEALw_wcB&gclsrc=aw.ds) and become a very good doctor!\n",
    "\n",
    "The Machine learning repository at the University of California, Irvine, has some great data sets. [Here](https://archive.ics.uci.edu/ml/datasets/SPECT+Heart) are data on cardiac Single Proton Emission Computed Tomography (SPECT) images that looks suspiciously similar to our caterpillar data. Each patient is classified into two categories: **normal** and **abnormal**.\n",
    "\n",
    "- *The dataset describes diagnosing of cardiac Single Proton Emission Computed Tomography (SPECT) images. Each of the patients is classified into two categories: normal and abnormal. The database of 267 SPECT image sets (patients) was processed to extract features that summarize the original SPECT images. As a result, 44 continuous feature pattern was created for each patient. The pattern was further processed to obtain 22 binary feature patterns. The CLIP3 algorithm was used to generate classification rules from these patterns. The CLIP3 algorithm generated rules that were 84.0% accurate (as compared with cardiologists' diagnoses)*. \n",
    "\n",
    "SPECT is a good data set for testing ML algorithms; it has 267 instances that are descibed by 23 binary attribute\n",
    "\n",
    "Our goal is to predict whether a person is categorized normal or abnormal based on 22 binary feature patterns. \n",
    "\n",
    "We should strive to ensure that our accuracy on test data is 70% or above (anything approaching 50% is junk: just a guess!).\n",
    "\n",
    "Let's recall our caterpillar learning algorithm:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "initialize weights\n",
    "loop until done\n",
    "  for each training item\n",
    "    compute Y\n",
    "    if correct do nothing\n",
    "    else if incorrect\n",
    "      if computed Y is too large\n",
    "        divide all relevant weights by 2.0\n",
    "      else if computed Y is too small\n",
    "        multiply all relevant weights by 2.0\n",
    "  end for\n",
    "end loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import our patient data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File data/SPECT.test does not exist: 'data/SPECT.test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d386fa2f4208>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/SPECT.test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File data/SPECT.test does not exist: 'data/SPECT.test'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data/SPECT.test\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First few lines of all data are:\")\n",
    "ShowMatrix(data.values, 0, 4, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = data['1']\n",
    "diagnosis.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the label from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.drop(labels='1', axis=1)\n",
    "data2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly split an 100-item encoded data set into an 80-item training set to generate the model. A 20-item test set is earmarked to evaluate the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting data into 80% train and 20% test matrices\")\n",
    "trainData, testData = MakeTrainTest(data2.values, 0.8, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First few rows of training data are:\")\n",
    "ShowMatrix(trainData, 0, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First few rows of testing data are:\")\n",
    "ShowMatrix(testData, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's *learn* our spectroscopy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Begin training using Caterpillar algorithm\")\n",
    "numInput = 16\n",
    "w = Caterpillar(numInput, 0) #rndSeed = 0\n",
    "weights = w.TrainWeights(trainData)\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final model weights are:\")\n",
    "ShowVector(weights, 4, 8, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAcc = w.Accuracy(trainData)\n",
    "testAcc = w.Accuracy(testData)\n",
    "\n",
    "print(\"Prediction accuracy on training data = \" + str(trainAcc))\n",
    "print(\"Prediction accuracy on test data = \" + str(testAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting diagnosis of patient with all abnormal readings: \", end='')\n",
    "yays = [ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ]\n",
    "predicted = w.ComputeY(yays)\n",
    "if predicted == 0:\n",
    "    print(\"normal\")\n",
    "else:\n",
    "    print(\"abnormal\")\n",
    "\n",
    "print(\"Predicting diagnosis of patient with all normal readings: \", end='')\n",
    "nays = [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]\n",
    "predicted2 = w.ComputeY(nays)\n",
    "if predicted2 == 0:\n",
    "    print(\"normal\")\n",
    "else:\n",
    "    print(\"abnormal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We assign weights based on each observation. Some abnormal features are going to be very discriminative about overll diagnosis, others much less so. The discriminative ones should acquire higher weights. The “*frivolous*” ones much less.\n",
    "\n",
    "The algorithm uses only incorrect information. Correct information (correct guess of a label) yields a `nop`. So the algorithm essentially drives the weights of irrelevant predictors to 0, *winnowing them out*. This makes Winnow classification effective in situations where many of the predictor variables are irrelevant (frivolous). It's a good way to figure out the important (discriminative) factors. Much like how regression forests told us what doctors should be looking at in correctly diagnosing breast cancer.\n",
    "\n",
    "See, even a simple caterpillar brain, as shallow as it is (*single layer*!), with a *linear* activation layer can learn a good data model.\n",
    "\n",
    "Our little Caterpillar model is the *simplest learning graph model* we know, and it has a name: It's called the Winnow.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"ipynb.images/winnow.png\" width=400 />\n",
    "</center>\n",
    "\n",
    "[Winnowing](https://en.wikipedia.org/wiki/Winnowing) means **removing unwanted items**. Its purpose as an algorthm is to train a binary classifier based on binary features, using a *linear* decision boundary.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"ipynb.images/winnow-ann.png\" width=400 />\n",
    "    Single-layer activation-less Winnow\n",
    "</center>\n",
    "\n",
    "## Idea\n",
    "Modify the Winnow so that instead of dividing or multiplying by 2, the increase or decrease in the weights is **proportional to the error**. Does this improve accuracy on the same dataset? On any other dataset?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
