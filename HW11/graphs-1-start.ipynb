{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Science Eng Methods and Tools, Lecture 11, Day 2</div>\n",
    "<div style=\"text-align: right\">Prof. Dino Konstantopoulos, 25 March 2020</div>\n",
    "\n",
    "# Graph theory and the dynamics of infections\n",
    "\n",
    "Modern [Graph theory](https://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg) was born in the city of St. Petersburg, Russia, where [Euler](https://en.wikipedia.org/wiki/Leonhard_Euler) lived. In this notebook, we will consider graph ***models***, which you now know is all about the ***phenomenon*** that generated the graph: Given the graph, what was its generating mechanism: an *inverse* problem, i.e. ***data science***!\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5d/Konigsberg_bridges.png\" width=400 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph has **nodes** (also called *vertices*) and **edges** that connect them. Edges can be **directed** (Twitter graphs), or not (facebook graphs).\n",
    "```(python)\n",
    "pip install networkx\n",
    "```\n",
    "Here is a simple graph that we create by creating edges from nodes. Note that as we create edges from nodes, if the nodes do not exist, they are automatically created (so, no need to create nodes because we don't really care about disconnected nodes!).\n",
    "\n",
    "We also assign a color to each node (because we are going to use colors to describe infection state for individuals). If the node is either `A`, `D`, or `H`, the color is prescribed, all other nodes default to 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(\n",
    "    [('A', 'B'), ('A', 'C'), ('D', 'B'), ('E', 'C'), ('E', 'F'),\n",
    "     ('B', 'H'), ('B', 'G'), ('B', 'F'), ('C', 'G')])\n",
    "\n",
    "val_map = {'A': 1.0,\n",
    "           'D': 0.5714285714285714,\n",
    "           'H': 0.0}\n",
    "\n",
    "values = [val_map.get(node, 0.25) for node in G.nodes()]\n",
    "\n",
    "nx.draw(G, cmap=plt.get_cmap('viridis'), node_color=values, with_labels=True, font_color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a cyclic graph, with 24 nodes and 24 node colors according to `matplotlib`'s `Blues` color map (`cm`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.cycle_graph(24)\n",
    "pos = nx.spring_layout(G, iterations=200)\n",
    "nx.draw(G, pos, node_color=range(24), node_size=800, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's dig deeper into graph types. \n",
    "\n",
    "## Graph types\n",
    "\n",
    "Networks are categorized by the [degrees] of their nodes. The degree distribution (pdf) $P(k)$ of a network is then defined to be the fraction of nodes in the network with degree $k$. The same information is also sometimes presented in the form of a **cumulative degree distribution** (cdf): The fraction of nodes with degree *smaller* than $k$.\n",
    "\n",
    ">**Definition**: The **degree** of a **node** in a network (sometimes referred to incorrectly as the **/connectivity*) is the number of connections or edges the node has to other nodes. Thus if there are $n$ nodes in total in a network and $n_k$ of them have degree $k$, then the probability that a node has degree $n_k$ is $P(k) = n_k/n$.\n",
    "\n",
    "The degree distribution is very important in studying networks. The simplest and most *beautiful* (可爱极了) network model, the [Erdős–Rényi graph](https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3%A9nyi_model) (ER) model, in which each of $n$ nodes is independently connected (or not) with probability $p$ (or $1 − p$), has a **binomial distribution of degrees k**:\n",
    "\n",
    "$$P(k) = (_k^{n-1}) p^k \\, (1-p)^{n-1-k}$$\n",
    "\n",
    "Recall that the binomial distribution with parameters $n$ and $k$ is the discrete probability distribution of the number of successes in a sequence of $n$ independent *and different* experiments, each asking a yes–no question, and each with its own boolean-valued outcome: success/yes/true/one with probability $k$ or failure/no/false/zero with probability $1 − k$.\n",
    "\n",
    "A single success/failure experiment is called a **Bernoulli trial** or Bernoulli experiment and a sequence of outcomes is called a Bernoulli process; for a single trial, i.e., $n = 1$, the binomial distribution is a Bernoulli distribution. \n",
    "\n",
    "> Suppose a *biased* (crooked) coin comes up heads with probability 0.3 when tossed. What is the probability of achieving (exactly) 5 heads after six tosses? It's \n",
    "\n",
    "$$0.3 * 0.3 * 0.3 * 0.3 * 0.3 * 0.7 +\\\\\n",
    "0.3 * 0.3 * 0.3 * 0.3 * 0.7 * 0.3 +\\\\\n",
    "0.3 * 0.3 * 0.3 * 0.7 * 0.3 * 0.3 +\\\\\n",
    "0.3 * 0.3 * 0.7 * 0.3 * 0.3 * 0.3 +\\\\\n",
    "0.3 * 0.7 * 0.3 * 0.3 * 0.3 * 0.3 +\\\\\n",
    "0.7 * 0.3 * 0.3 * 0.3 * 0.3 * 0.3 \\\\\n",
    "= 6 * 0.001701 = 0.010206$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import factorial\n",
    "\n",
    "def choose(n, c):\n",
    "    \"\"\"Number of ways to choose c items from a list of n items.\"\"\"\n",
    "    return factorial(n) // (factorial(n - c) * factorial(c))\n",
    "choose(6, 5) * 0.3**5 * 0.7**1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binomial distribution is important when ***ordering matters***. If ordering does not matter, and *all I care about is the count* of `yes`es and `no`s, then the **binomial distribution** looses its `choose` factor and becomes the **Bernoulli distribution**:\n",
    "\n",
    "$$P(k) = p^k \\, (1-p)^{n-1-k}$$\n",
    "\n",
    "If I have to determine whether a coin is biased or not, I *do not care* about the ordering of heads and tails, I will just *count the number* of heads and tails to determine crookedness. That was the primary source confusion in your midterm between Binomial and Bernoulli.\n",
    "\n",
    "In the case of **graphs**, I can have 1, 2, 3, 4, 5, 6, 7, etc.. number of neighbors and each graph will have a different distribution of 1s, 2s, 3s, 4s, 5s, 6s, 7s, etc.  So the simplest possible (and thus most beautiful) graph degree distribution is the binomial, which essentially says that the probability of having an edge is fixed.\n",
    "\n",
    "Here below is a random graph with degree 3 (meaning *every node has 3 neighbors*). Count them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.random_regular_graph(3, 50)\n",
    "nx.draw_spring(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"visibility: hidden\">\n",
    "The sum of the node degree values is twice the number of edges (see [here](https://en.wikipedia.org/wiki/Modularity_(networks)#Expected_Number_of_Edges_Between_Nodes)), because each of the edges has been counted from both ends.\n",
    "\n",
    "50 nodes of degree 3 mean there are (50×3)/2=75 edges\n",
    "```(python)\n",
    "nx.number_of_edges(g)\n",
    "```\n",
    "\n",
    "How many [regions](https://en.wikipedia.org/wiki/Euler_characteristic) are there in a graph has if it has v nodes and e edges? The answer is r=e−v+2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, compute the number of edges of the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is what a 50-node Erdős–Rényi graph (where nodes now have a probabilistic degree *distribution*) looks like. Verify that nodes now have *varying* numbers of edges (neighbors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.erdos_renyi_graph(50, .15)\n",
    "nx.draw_spring(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is what a 200-node Erdős–Rényi graph looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.erdos_renyi_graph(200, .15)\n",
    "nx.draw_spring(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with a little bit of artificial tension along the edges (` nx.spring_layout()`), we can make it look prettier. Also, we color the nodes by how far away they are from the center node (colored white)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position is stored as node attribute data for random_geometric_graph\n",
    "pos = nx.spring_layout(G)\n",
    "#print(pos)\n",
    "\n",
    "# find node near center (0.5,0.5)\n",
    "dmin=1\n",
    "ncenter=0\n",
    "for n in pos:\n",
    "    x,y=pos[n]\n",
    "    d=(x-0.5)**2+(y-0.5)**2\n",
    "    if d<dmin:\n",
    "        ncenter=n\n",
    "        dmin=d\n",
    "print(ncenter)\n",
    "        \n",
    "# color by path length from node near center\n",
    "p=nx.single_source_shortest_path_length(g, ncenter)\n",
    "#print(p.values())\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "nx.draw_networkx_edges(g,pos,nodelist=[ncenter],alpha=0.1)\n",
    "nx.draw_networkx_nodes(g,pos,nodelist=p.keys(),\n",
    "                       node_size=80,\n",
    "                       node_color=list(p.values()),\n",
    "                       cmap=plt.cm.Blues)\n",
    "\n",
    "#plt.xlim(-0.05,1.05)\n",
    "#plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **random graph** on the other hand is one where each node has a **normal** probability of having a set number of neighbors. In other words, there is a specific degree (the **mean** of the normal pdf) that will occur much more often than others.\n",
    "\n",
    "Making a random network is super-easy: Take $n$ nodes and $m$ pairs at random and place the edges between the randomly chosen nodes. Also, you could take $n$ nodes, compute a probability $p$ (from a normal distribution), and create an edge at random to another node.\n",
    "\n",
    "The Erdős–Rényi graph is a special case where the probability for edge creation $p$ is fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating big graphs *fast* confers an important advantage. Drawing them takes a lot longer. \n",
    "\n",
    "[This](https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html) is how you can profile the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "g = nx.fast_gnp_random_graph(1000, .15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, ***don't*** run this operation in class, it will take tens of minutes to create a graph of 10,000 nodes with ... edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time nx.fast_gnp_random_graph(10000, .15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this one instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time nx.fast_gnp_random_graph(1000, .15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time nx.draw_spring(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find some `networkx` graph generators [here](https://networkx.github.io/documentation/networkx-0.37/networkx.generators.random_graphs-pysrc.html).\n",
    "\n",
    "[A small world](https://en.wikipedia.org/wiki/ASmallWorld) was founded in 2004 as one of the first social networks (long before facebook), and is the leading invitation-only Travel and Lifestyle online community.\n",
    "\n",
    "Duncan Watts and Steven Strogatz built a [small world graph model](https://en.wikipedia.org/wiki/Watts%E2%80%93Strogatz_model): a few random links in an otherwise structured graph make the\n",
    "network a small world: the average shortest path is short.\n",
    "\n",
    "Why did they build this?\n",
    "\n",
    " ER graphs do not have two important properties observed in many real-world networks:\n",
    "\n",
    "- They do not generate **local clustering** and **triadic closures**. Instead, because they have a constant, random, and independent probability of two nodes being connected, ER graphs have a low clustering coefficient.\n",
    "- They do not account for the formation of hubs. Formally, the degree distribution of ER graphs converges to a Poisson distribution, rather than a power law observed in many real-world, scale-free networks.\n",
    "\n",
    "The Watts and Strogatz (WS) model was designed as the simplest possible model that addresses the first of the two limitations. It accounts for clustering while retaining the short average path lengths of the ER model. It does so by interpolating between a randomized structure close to ER graphs and a regular ring lattice. Consequently, the model is able to at least partially explain the \"*small-world*\" phenomena in a variety of networks, such as the power grid, neural network of C. elegans, networks of movie actors, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.watts_strogatz_graph(50, 5, .15)\n",
    "nx.draw_spring(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the second weakness of ER graphs, the [Barabási–Albert](https://en.wikipedia.org/wiki/Barab%C3%A1si%E2%80%93Albert_model) (BA) model is an algorithm for generating random scale-free networks using a preferential attachment mechanism. What this means is that essentially *many professors want to marry Rihanna*. In other words, some nodes are reall attractors for all nodes, which want to create an edge with them.\n",
    "\n",
    "Several natural and human-made systems, including the Internet, the world wide web, citation networks, and some social networks are thought to be approximately scale-free and certainly contain few nodes (called hubs) with unusually high degree as compared to the other nodes of the network. The BA model tries to explain the existence of such nodes in real networks. The algorithm is named for its inventors [Albert-László Barabási](https://en.wikipedia.org/wiki/Albert-L%C3%A1szl%C3%B3_Barab%C3%A1si) and Réka Albert and is a special case of an earlier and more general model called Price's model.\n",
    "\n",
    "The way to create a BA graph of n nodes is to grow it by attaching new nodes each with m edges that are preferentially attached to existing nodes with high degree. Not all nodes will have m neighbors. The initialization is a graph with with m nodes and no edges. Graph creation stops when you reach $n$ nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.barabasi_albert_graph(30, 5)\n",
    "nx.draw_spring(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.barabasi_albert_graph(200, 5)\n",
    "nx.draw_spring(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position is stored as node attribute data for random_geometric_graph\n",
    "pos = nx.spring_layout(G)\n",
    "#print(pos)\n",
    "\n",
    "# find node near center (0.5,0.5)\n",
    "dmin=1\n",
    "ncenter=0\n",
    "for n in pos:\n",
    "    x,y=pos[n]\n",
    "    d=(x-0.5)**2+(y-0.5)**2\n",
    "    if d<dmin:\n",
    "        ncenter=n\n",
    "        dmin=d\n",
    "print(ncenter)\n",
    "        \n",
    "# color by path length from node near center\n",
    "p=nx.single_source_shortest_path_length(g,ncenter)\n",
    "#print(p.values())\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "nx.draw_networkx_edges(g,pos,nodelist=[ncenter],alpha=0.1)\n",
    "nx.draw_networkx_nodes(g,pos,nodelist=p.keys(),\n",
    "                       node_size=80,\n",
    "                       node_color=list(p.values()),\n",
    "                       cmap=plt.cm.Blues)\n",
    "\n",
    "#plt.xlim(-0.05,1.05)\n",
    "#plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [geometric graph](https://networkx.github.io/documentation/stable/reference/generated/networkx.generators.geometric.random_geometric_graph.html) (GG) is grown in an interesting way: The graph model places n nodes uniformly at random in the unit cube. Two nodes are joined by an edge if the distance between the nodes is at most radius. Edges are determined using a `KDTree` when `SciPy` is available. This reduces the time complexity from O($4n^2$) to O($n$).\n",
    "\n",
    "This is an interesting graph for us because it is the beginning of how we could randomly place people in a city. We will then modify this graph by clustering people into appartment buildings.\n",
    "\n",
    "The graph is undirected and without self-loops. Each node has a node attribute `pos` that stores the position of that node in Euclidean space as provided by the `pos` API keyword argument or, if `pos` was not provided, as generated by `random_geometric_graph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.random_geometric_graph(200, 0.125)\n",
    "# position is stored as node attribute data for random_geometric_graph\n",
    "pos=nx.get_node_attributes(G,'pos')\n",
    "\n",
    "# find node near center (0.5,0.5)\n",
    "dmin=1\n",
    "ncenter=0\n",
    "for n in pos:\n",
    "    x,y=pos[n]\n",
    "    d=(x-0.5)**2+(y-0.5)**2\n",
    "    if d<dmin:\n",
    "        ncenter=n\n",
    "        dmin=d\n",
    "\n",
    "# color by path length from node near center\n",
    "p=nx.single_source_shortest_path_length(G,ncenter)\n",
    "#print(p.values())\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "nx.draw_networkx_edges(G,pos,nodelist=[ncenter],alpha=0.4)\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=p.keys(),\n",
    "                       node_size=80,\n",
    "                       node_color=list(p.values()),\n",
    "                       cmap=plt.cm.Blues)\n",
    "\n",
    "plt.xlim(-0.05,1.05)\n",
    "plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.random_geometric_graph(2000, 0.125)\n",
    "# position is stored as node attribute data for random_geometric_graph\n",
    "pos=nx.get_node_attributes(G,'pos')\n",
    "\n",
    "# find node near center (0.5,0.5)\n",
    "dmin=1\n",
    "ncenter=0\n",
    "for n in pos:\n",
    "    x,y=pos[n]\n",
    "    d=(x-0.5)**2+(y-0.5)**2\n",
    "    if d<dmin:\n",
    "        ncenter=n\n",
    "        dmin=d\n",
    "\n",
    "# color by path length from node near center\n",
    "p=nx.single_source_shortest_path_length(G,ncenter)\n",
    "#print(p.values())\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "nx.draw_networkx_edges(G,pos,nodelist=[ncenter],alpha=0.1)\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=p.keys(),\n",
    "                       node_size=80,\n",
    "                       node_color=list(p.values()),\n",
    "                       cmap=plt.cm.Blues)\n",
    "\n",
    "plt.xlim(-0.05,1.05)\n",
    "plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many neighbors per node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.neighbors(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighs = []\n",
    "for node_id in G.nodes():\n",
    "     neighs.append(len(list(G.neighbors(node_id))))\n",
    "','.join(str(_) for _ in neighs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(neighs)/2000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better metric is the **average degree** of the ***neighborhood*** of each node $i$:\n",
    "\n",
    "$$k_{nn,i} = \\frac{1}{|N(i)|}\\, \\sum_{j \\in N(i)} k_j$$\n",
    "\n",
    "where $N(i)$ are the neighbors of node $i$ and $k_j$ is the degree of node $j$ which belongs to $N(i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "take(20, nx.average_neighbor_degree(G).items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average number of neighbors for the graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(nx.average_neighbor_degree(G).values()) / 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same graph generator, except it also specified a `p` paramter (float, optional) – The [Minkowski distance](https://en.wikipedia.org/wiki/Minkowski_distance) metric (a generalization of both Euclidean distance and Manhattan distance) to use ($p$ has to meet the condition $1 <= p <= \\infty$). Since we did not specify this argument above, the L2 metric (the Euclidean distance metric), $p = 2$ was used (his should not be confused with the p of an Erdős-Rényi random graph, which represents probability).\n",
    "\n",
    "The higher the `p`, the more bewildering the graph since it's constructed in a convex space that brings objects closer together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.random_geometric_graph(200, 0.125, p=7)\n",
    "# position is stored as node attribute data for random_geometric_graph\n",
    "pos=nx.get_node_attributes(G,'pos')\n",
    "\n",
    "# find node near center (0.5,0.5)\n",
    "dmin=1\n",
    "ncenter=0\n",
    "for n in pos:\n",
    "    x,y=pos[n]\n",
    "    d=(x-0.5)**2+(y-0.5)**2\n",
    "    if d<dmin:\n",
    "        ncenter=n\n",
    "        dmin=d\n",
    "\n",
    "# color by path length from node near center\n",
    "p=nx.single_source_shortest_path_length(G,ncenter)\n",
    "#print(p.values())\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "nx.draw_networkx_edges(G,pos,nodelist=[ncenter],alpha=0.4)\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=p.keys(),\n",
    "                       node_size=80,\n",
    "                       node_color=list(p.values()),\n",
    "                       cmap=plt.cm.Blues)\n",
    "\n",
    "plt.xlim(-0.05,1.05)\n",
    "plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Geometric graph **+** (GG+) is my own invention. It grows like a geometric graph, except that it adds *superclusters* (clusters of supernodes), which are nodes with much denser neighborhoods. Think of these clusters as supermarkets, movie theatres, or rock concerts.\n",
    "\n",
    "The more appropriate model would be a dynamic model, where superclusters coalesce and disintegrate in time. But let's start with simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.random_geometric_graph(200, 0.125)\n",
    "pos=nx.get_node_attributes(G,'pos')\n",
    "\n",
    "# find node near center (0.5,0.5)\n",
    "dmin=1\n",
    "ncenter=0\n",
    "for n in pos:\n",
    "    x,y=pos[n]\n",
    "    d=(x-0.5)**2+(y-0.5)**2\n",
    "    if d<dmin:\n",
    "        ncenter=n\n",
    "        dmin=d\n",
    "\n",
    "# color by path length from node near center\n",
    "p=nx.single_source_shortest_path_length(G,ncenter)\n",
    "#print(p.values())\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "nx.draw_networkx_edges(G,pos,nodelist=[ncenter],alpha=0.4)\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=p.keys(),\n",
    "                       node_size=80,\n",
    "                       node_color=list(p.values()),\n",
    "                       cmap=plt.cm.Blues)\n",
    "\n",
    "plt.xlim(-0.05,1.05)\n",
    "plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph has an average of about 10 neighbors per node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(nx.average_neighbor_degree(G).values()) / 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation is very small, though (meaning *all* nodes have about the same number of neighbors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take(10, nx.average_neighbor_degree(G).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = [y for x,y in take(20, nx.average_neighbor_degree(G).items())]\n",
    "np.std(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's *change that*! We do some prototyping, first:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def random_edge(graph, del_orig=True):\n",
    "    '''\n",
    "    Create a new random edge and delete one of its current edge if del_orig is True.\n",
    "    :param graph: networkx graph\n",
    "    :param del_orig: bool\n",
    "    :return: networkx graph\n",
    "    '''\n",
    "    edges = list(graph.edges)\n",
    "    nonedges = list(nx.non_edges(graph))\n",
    "\n",
    "    # random edge choice\n",
    "    chosen_edge = random.choice(edges)\n",
    "    chosen_nonedge = random.choice([x for x in nonedges if chosen_edge[0] == x[0]])\n",
    "\n",
    "    if del_orig:\n",
    "        # delete chosen edge\n",
    "        graph.remove_edge(chosen_edge[0], chosen_edge[1])\n",
    "    # add new edge\n",
    "    graph.add_edge(chosen_nonedge[0], chosen_nonedge[1])\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_remove_edges(G, p_new_connection, p_remove_connection):    \n",
    "    '''    \n",
    "    for each node,    \n",
    "      add a new connection to random other node, with prob p_new_connection,    \n",
    "      remove a connection, with prob p_remove_connection    \n",
    "\n",
    "    operates on G in-place    \n",
    "    '''                \n",
    "    new_edges = []    \n",
    "    rem_edges = []    \n",
    "\n",
    "    for node in G.nodes():    \n",
    "        # find the other nodes this one is connected to    \n",
    "        connected = [to for (fr, to) in G.edges(node)]    \n",
    "        # and find the remainder of nodes, which are candidates for new edges   \n",
    "        unconnected = [n for n in G.nodes() if not n in connected]    \n",
    "\n",
    "        # probabilistically add a random edge    \n",
    "        if len(unconnected): # only try if new edge is possible    \n",
    "            if random.random() < p_new_connection:    \n",
    "                new = random.choice(unconnected)    \n",
    "                G.add_edge(node, new)    \n",
    "                print (\"\\tnew edge:\\t {} -- {}\".format(node, new))  \n",
    "                new_edges.append( (node, new) )    \n",
    "                # book-keeping, in case both add and remove done in same cycle  \n",
    "                unconnected.remove(new)    \n",
    "                connected.append(new)    \n",
    "\n",
    "        # probabilistically remove a random edge    \n",
    "        if len(connected): # only try if an edge exists to remove    \n",
    "            if random.random() < p_remove_connection:    \n",
    "                remove = random.choice(connected)    \n",
    "                G.remove_edge(node, remove)    \n",
    "                print (\"\\tedge removed:\\t {} -- {}\".format(node, remove))  \n",
    "                rem_edges.append( (node, remove) )    \n",
    "                # book-keeping, in case lists are important later?    \n",
    "                connected.remove(remove)    \n",
    "                unconnected.append(remove)    \n",
    "    return rem_edges, new_edges    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "p_new_connection = 0.1\n",
    "p_remove_connection = 0.\n",
    "\n",
    "G = nx.karate_club_graph() # sample graph (undirected, unweighted)\n",
    "# show original\n",
    "plt.figure(1); plt.clf()\n",
    "fig, ax = plt.subplots(2,1, num=1, sharex=True, sharey=True)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw_networkx(G, pos=pos, ax=ax[0])\n",
    "\n",
    "# now apply one round of changes\n",
    "rem_edges, new_edges = add_and_remove_edges(G, p_new_connection, p_remove_connection)\n",
    "\n",
    "# and draw new version and highlight changes\n",
    "nx.draw_networkx(G, pos=pos, ax=ax[1])\n",
    "nx.draw_networkx_edges(G, pos=pos, ax=ax[1], edgelist=new_edges,\n",
    "                       edge_color='b', width=4)\n",
    "# note: to highlight edges that were removed, add them back in;\n",
    "# This is obviously just for display!\n",
    "G.add_edges_from(rem_edges)\n",
    "nx.draw_networkx_edges(G, pos=pos, ax=ax[1], edgelist=rem_edges,\n",
    "                       edge_color='r', style='dashed', width=4)\n",
    "G.remove_edges_from(rem_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = [y for x,y in take(20, nx.average_neighbor_degree(G).items())]\n",
    "np.mean(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this seems to work, so let's modify `add_and_remove_edges` to create super-clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_superclusters(G, p_new_supercluster, p_new_connection, cluster_max_size):    \n",
    "    '''    \n",
    "    for each node,\n",
    "      if it probabilistically becomes a supercluster with prob p_new_supercluster,\n",
    "        add a new connection to a random number (less than cluster_max_size) of other nodes, with prob p_new_connection    \n",
    "\n",
    "    operates on G in-place    \n",
    "    '''                \n",
    "    new_edges = []      \n",
    "\n",
    "    for node in G.nodes(): \n",
    "        if random.random() < p_new_supercluster:\n",
    "            \n",
    "            # find the other nodes this one is connected to    \n",
    "            connected = [to for (fr, to) in G.edges(node)]    \n",
    "            # and find the remainder of nodes, which are candidates for new edges   \n",
    "            unconnected = [n for n in G.nodes() if not n in connected]    \n",
    "\n",
    "            # probabilistically add a random edge  \n",
    "            how_many = cluster_max_size\n",
    "            while 0 < len(unconnected) and 0 < how_many: # only try if new edge is possible    \n",
    "                if random.random() < p_new_connection:    \n",
    "                    new = random.choice(unconnected)    \n",
    "                    G.add_edge(node, new)    \n",
    "                    print (\"\\tnew edge:\\t {} -- {}\".format(node, new))  \n",
    "                    new_edges.append( (node, new) )    \n",
    "                    # book-keeping, in case both add and remove done in same cycle  \n",
    "                    unconnected.remove(new)    \n",
    "                    connected.append(new)\n",
    "                how_many -= 1\n",
    "   \n",
    "    return new_edges    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_new_supercluster = 0.6\n",
    "p_new_connection = 0.3\n",
    "cluster_max_size = 20\n",
    "\n",
    "G = nx.karate_club_graph() # sample graph (undirected, unweighted)\n",
    "# show original\n",
    "plt.figure(1); plt.clf()\n",
    "fig, ax = plt.subplots(2,1, num=1, sharex=True, sharey=True)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw_networkx(G, pos=pos, ax=ax[0])\n",
    "\n",
    "# now apply one round of changes\n",
    "new_edges = add_superclusters(G, p_new_supercluster, p_new_connection, cluster_max_size)\n",
    "\n",
    "# and draw new version and highlight changes\n",
    "nx.draw_networkx(G, pos=pos, ax=ax[1])\n",
    "nx.draw_networkx_edges(G, pos=pos, ax=ax[1], edgelist=new_edges,\n",
    "                       edge_color='b', width=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = [y for x,y in take(20, nx.average_neighbor_degree(G).items())]\n",
    "np.mean(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply to a geometric graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.random_geometric_graph(200, 0.125)\n",
    "pos=nx.get_node_attributes(G,'pos')\n",
    "\n",
    "# find node near center (0.5,0.5)\n",
    "dmin=1\n",
    "ncenter=0\n",
    "for n in pos:\n",
    "    x,y=pos[n]\n",
    "    d=(x-0.5)**2+(y-0.5)**2\n",
    "    if d<dmin:\n",
    "        ncenter=n\n",
    "        dmin=d\n",
    "\n",
    "# color by path length from node near center\n",
    "p=nx.single_source_shortest_path_length(G,ncenter)\n",
    "#print(p.values())\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "nx.draw_networkx_edges(G,pos,nodelist=[ncenter],alpha=0.4)\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=p.keys(),\n",
    "                       node_size=80,\n",
    "                       node_color=list(p.values()),\n",
    "                       cmap=plt.cm.Blues)\n",
    "\n",
    "plt.xlim(-0.05,1.05)\n",
    "plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_new_supercluster = 0.01\n",
    "p_new_connection = 0.2\n",
    "cluster_max_size = 40\n",
    "\n",
    "# now apply one round of changes\n",
    "new_edges = add_superclusters(G, p_new_supercluster, p_new_connection, cluster_max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw new version and highlight changes\n",
    "\n",
    "# color by path length from node near center\n",
    "p=nx.single_source_shortest_path_length(G,ncenter)\n",
    "#print(p.values())\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "nx.draw_networkx_edges(G,pos,nodelist=[ncenter],alpha=0.4)\n",
    "nx.draw_networkx_nodes(G,pos,nodelist=p.keys(),\n",
    "                       node_size=80,\n",
    "                       node_color=list(p.values()),\n",
    "                       cmap=plt.cm.Blues)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos=pos, edgelist=new_edges,\n",
    "                       edge_color='b', width=1)\n",
    "\n",
    "plt.xlim(-0.05,1.05)\n",
    "plt.ylim(-0.05,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here how superclusters bring nodes into contact that would usually not be in contact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label propagation\n",
    "\n",
    "In **Node Classification**, we are given a network that is composed of a set of nodes and a set of edges. The important aspect of this problem is that some part of nodes are given their labels, and some *not*. What we want to do here is to predict the colors (labels) of the unlabeled nodes.\n",
    "\n",
    "Label Propagation tries to find the optimal coloring that satisfies the following two constraints:\n",
    "- Constraint1: A node that is given its label must not change its label.\n",
    "- Constraint2: A pair of connected nodes should have the same labels.\n",
    "\n",
    "Constraint1 is simple. It just states that the color given to a node must not change. Constraint2 is the core of this algorithm. If a node has a connection with another node whose color is red, the first node should also be red. Note that the first constraint is *must*, but the second constraint is *should*. So we will find the coloring that *minimizes* the number of violations of Constraint2 without *no* violations of Constraint1.\n",
    "\n",
    "Find all available `matplotlib` colormaps [here](https://matplotlib.org/examples/color/colormaps_reference.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "edges = [('A','X'), ('B','X'), ('X','Y'), ('C','X'), ('C','Y'), ('D','Y')]\n",
    "G.add_edges_from(edges)\n",
    "G.nodes['A']['label'] = 'RED'\n",
    "G.nodes['B']['label'] = 'RED'\n",
    "G.nodes['C']['label'] = 'BLUE'\n",
    "G.nodes['D']['label'] = 'RED'\n",
    "G.nodes['X']['label'] = None\n",
    "G.nodes['Y']['label'] = None\n",
    "\n",
    "val_map = {'A': 1.0,\n",
    "           'B': 1.0,\n",
    "           'C': 0.0,\n",
    "           'D': 1.0}\n",
    "\n",
    "values = [val_map.get(node, 0.5) for node in G.nodes()]\n",
    "\n",
    "nx.draw(G, cmap=plt.get_cmap('bwr'), node_color=values, with_labels=True, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paint the unpainted nodes blue, and count the violations. How many?\n",
    "\n",
    "Then paint one red, the other blue, then one blue, the other red. How many constraint violations?\n",
    "\n",
    "Then paint both red, how many constraint violations?\n",
    "\n",
    "So, which is the optimal solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's devise an algoithm to solve this automatically.\n",
    "\n",
    "Let’s initialize \"*scores*\" for each node: Red nodes are assigned score 0, blue nodes are assigned score 1, and unlabeled nodes are assigned score init_value (here, 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_scores(g, init_value):\n",
    "    for node_id in g.nodes():\n",
    "        label = g.nodes[node_id]['label']\n",
    "        if label == 'RED':\n",
    "            # Labeled nodes: RED\n",
    "            g.nodes[node_id]['score'] = 1\n",
    "        elif label == 'BLUE':\n",
    "            # Labeled nodes: BLUE\n",
    "            g.nodes[node_id]['score'] = 0\n",
    "        else:\n",
    "            # Unlabeled nodes\n",
    "            g.nodes[node_id]['score'] = init_value\n",
    "\n",
    "initialize_scores(G, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's *propagate* the scores (labels). Recall that the score of an unlabeled node is calculated by taking the average scores of all neighbors. Let’s define a function to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_score(g, node_id):\n",
    "    score_sum = 0\n",
    "    n_neighbors = 0\n",
    "    for neighbor_id in g[node_id]:\n",
    "        score_sum += g.nodes[neighbor_id]['score']\n",
    "        n_neighbors += 1\n",
    "    return score_sum / n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_avg_score(G, 'X') # => 0.625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_avg_score(G, 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [G.nodes[node_id]['score'] for node_id in G.nodes()]\n",
    "\n",
    "nx.draw(G, cmap=plt.get_cmap('bwr'), node_color=values, with_labels=True, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let’s define a function `propagate` that performs one step of propagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(g):\n",
    "    next_scores = {}\n",
    "    for node_id in g.nodes():\n",
    "        if g.nodes[node_id]['label'] is not None:\n",
    "            # scores of labeled nodes do not change\n",
    "            next_scores[node_id] = g.nodes[node_id]['score']\n",
    "        else:\n",
    "            next_scores[node_id] = calculate_avg_score(g, node_id)\n",
    "    for node_id in next_scores:\n",
    "        g.nodes[node_id]['score'] = next_scores[node_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform one step of propagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propagate(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [G.nodes[node_id]['score'] for node_id in G.nodes()]\n",
    "\n",
    "nx.draw(G, cmap=plt.get_cmap('bwr'), node_color=values, with_labels=True, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s run 10 steps and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10\n",
    "for i in range(n_steps):\n",
    "    propagate(G)\n",
    "    print(\"=== After {} steps ===\".format(i+1))\n",
    "    print(\"X = {}\".format(G.nodes['X']['score']))\n",
    "    print(\"Y = {}\".format(G.nodes['Y']['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [G.nodes[node_id]['score'] for node_id in G.nodes()]\n",
    "\n",
    "nx.draw(G, cmap=plt.get_cmap('bwr'), node_color=values, with_labels=True, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 10 steps, the scores mostly converged (if we run again, scores don't change):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propagate(G)\n",
    "print(\"=== After one more step ===\")\n",
    "print(\"X = {}\".format(G.nodes['X']['score']))\n",
    "print(\"Y = {}\".format(G.nodes['Y']['score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's bump the scores to the nearest integer and re-paint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bump_score(g):\n",
    "    for node_id in g.nodes():\n",
    "         g.nodes[node_id]['score'] = int(round(g.nodes[node_id]['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bump_score(G)\n",
    "\n",
    "values = [G.nodes[node_id]['score'] for node_id in G.nodes()]\n",
    "\n",
    "nx.draw(G, cmap=plt.get_cmap('bwr'), node_color=values, with_labels=True, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's the solution we were afer!\n",
    "\n",
    "So now we have an ability to predict the labels of nodes.\n",
    "\n",
    "To deal with networks with 3 or more labels, we can use the [node_classification](https://networkx.github.io/documentation/stable/reference/algorithms/node_classification.html) module in `NetworkX` version 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "edges = [('A','X'), ('B','X'), ('X','Y'), ('C','X'), ('C','Y'), ('D','Y')]\n",
    "G.add_edges_from(edges)\n",
    "G.nodes['A']['label'] = 1.0\n",
    "G.nodes['B']['label'] = 1.0\n",
    "G.nodes['C']['label'] = 0.1\n",
    "G.nodes['D']['label'] = 1.0\n",
    "G.nodes['X']['label'] = None\n",
    "G.nodes['Y']['label'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import node_classification\n",
    "#G = nx.path_graph(4)\n",
    "#G.edges()\n",
    "#EdgeView([(0, 1), (1, 2), (2, 3)])\n",
    "#G.nodes[0]['label'] = 'A'\n",
    "#G.nodes[3]['label'] = 'B'\n",
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_classification.harmonic_function(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm.. don't really know how to use this API.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics of infections\n",
    "\n",
    "Let's build a geometric graph with nodes in 4 different states: `S`usceptible, `I`nfected, `R`ecovered, and `D`dead. We begin our simulation with all nodes susceptible, except for one in Hubei, China, which is infected. We then propagate the infection according to the characteristics of CoVid19 as we computed them in our previous notebook.\n",
    "\n",
    ">**NOTE**: This is similar to a cellular automation, except the topology is a graph instead of Euclidian space.\n",
    "\n",
    "We will study the propagation of the infection as a function of different graph types: An ER graph, a WS graph, a BA graph, a GG graph, and a GG+ graph. We see where the infection grows faster, and where it is curtailed. We then build models of protection for citizens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "nx.number_of_nodes(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(g):\n",
    "    for node_id in g.nodes():\n",
    "        g.nodes[node_id]['touched'] = 0\n",
    "        g.nodes[node_id]['state'] = 0\n",
    "\n",
    "seed(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_infection(g, p_Hubei):\n",
    "    for node_id in g.nodes():\n",
    "        if random.random() < p_Hubei:\n",
    "            g.nodes[node_id]['state'] = 1\n",
    "            print('node ' + str(node_id) + ' infected!')\n",
    "            return node_id\n",
    "        else:\n",
    "            print('node ' + str(node_id) + ' healthy.')\n",
    "    return -1\n",
    "\n",
    "seed_infection(G, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)\n",
    "values = [G.nodes[node_id]['state'] for node_id in G.nodes()]\n",
    "nx.draw(G, pos, cmap=plt.get_cmap('bwr'), node_color=values, with_labels=True, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just consider infections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_infection(g, beta):\n",
    "    num_infected = 0\n",
    "    for node_id in g.nodes():\n",
    "        if 1 == g.nodes[node_id]['state']:\n",
    "            p_infection = beta / len(list(g.neighbors(node_id)))\n",
    "            for neighbor_id in g[node_id]:\n",
    "                if random.random() < p_infection:\n",
    "                    g.nodes[neighbor_id]['state'] = 1\n",
    "                    num_infected += 1\n",
    "    return num_infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propagate_infection(G, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [G.nodes[node_id]['state'] for node_id in G.nodes()]\n",
    "nx.draw(G, pos, cmap=plt.get_cmap('bwr'), node_color=values, with_labels=True, font_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(propagate_infection(G, 1))\n",
    "values = [G.nodes[node_id]['state'] for node_id in G.nodes()]\n",
    "nx.draw(G, pos, cmap=plt.get_cmap('bwr'), node_color=values, with_labels=True, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider infections, recoveries, and deaths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_infection(g, p_Hubei, how_many_infected):\n",
    "    infected = []\n",
    "    for node_id in g.nodes():\n",
    "        g.nodes[node_id]['touched'] = 0\n",
    "        if random.random() < p_Hubei and 0 < how_many_infected:\n",
    "            g.nodes[node_id]['state'] = 'infected'\n",
    "            print('node ' + str(node_id) + ' infected!', 'With ' + str(len(list(G.neighbors(node_id)))) + ' neighbors')\n",
    "            infected.append(node_id)\n",
    "            how_many_infected -= 1\n",
    "        else:\n",
    "            g.nodes[node_id]['state'] = 'susceptible'\n",
    "            #print('node ' + str(node_id) + ' healthy.', g.nodes[node_id]['state'])\n",
    "    return how_many_infected\n",
    "\n",
    "def seed_infection(g, n, verbosity=0):\n",
    "    g.nodes[n]['state'] = 'infected'\n",
    "    g.nodes[n]['touched'] = 0\n",
    "    if 0 < verbosity: print('node ' + str(n) + ' infected!', 'With ' + str(len(list(G.neighbors(n)))) + ' neighbors')\n",
    "    for node_id in g.nodes():\n",
    "        if node_id != n:\n",
    "            g.nodes[node_id]['state'] = 'susceptible'\n",
    "            g.nodes[node_id]['touched'] = 0\n",
    "\n",
    "#if 1 == seed_infection(G, 0.05, 1): print('*** noone infeected! Please rerun.')\n",
    "seed_infection(G, 0, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all nodes are only processed once (using g.nodes[neighbor_id]['touched'] flag)\n",
    "def propagate_infection(g, beta, gamma, r, f, verbosity = 0):\n",
    "    num_infected = 0\n",
    "    for node_id in g.nodes():\n",
    "        if 0 < verbosity: print(str(node_id), g.nodes[node_id]['state'])\n",
    "        if 'infected' == g.nodes[node_id]['state'] and 0 == g.nodes[node_id]['touched']:\n",
    "            if 0 < verbosity: print('in infected clause..')\n",
    "            p_infection = beta / len(list(g.neighbors(node_id)))\n",
    "            p_reinfection = beta / len(list(g.neighbors(node_id))) / 10.\n",
    "            p_recovery = r \n",
    "            p_death = f\n",
    "            \n",
    "            # first, neighbor disposition\n",
    "            for neighbor_id in g[node_id]:\n",
    "                if 'recovered' == g.nodes[neighbor_id]['state'] and 0 == g.nodes[neighbor_id]['touched']:  ##temporary immunity\n",
    "                    if 0 < verbosity: print('in recovered neighbor..')\n",
    "                    if random.random() < p_reinfection:\n",
    "                        g.nodes[neighbor_id]['state'] = 'infected'  #neighbor reinfected!\n",
    "                        g.nodes[neighbor_id]['touched'] = 1\n",
    "                        if 0 < verbosity: print('****** reinfected a neighbor!')\n",
    "                        num_infected += 1\n",
    "                elif 'susceptible' == g.nodes[neighbor_id]['state'] and 0 == g.nodes[neighbor_id]['touched']:\n",
    "                    if 0 < verbosity: print('in susceptible neighbor..')\n",
    "                    if random.random() < p_infection:\n",
    "                        g.nodes[neighbor_id]['state'] = 'infected'  #neighbor infected\n",
    "                        g.nodes[neighbor_id]['touched'] = 1\n",
    "                        if 0 < verbosity: print('*** infected a neighbor!')\n",
    "                        num_infected += 1\n",
    "                        \n",
    "            # then, self-disposition              \n",
    "            if random.random() < p_recovery:\n",
    "                g.nodes[node_id]['state'] = 'recovered'\n",
    "                g.nodes[node_id]['touched'] = 1\n",
    "                if 0 < verbosity: print('recovered!')\n",
    "            elif random.random() < p_death:\n",
    "                g.nodes[node_id]['state'] = 'dead'\n",
    "                g.nodes[node_id]['touched'] = 1\n",
    "                if 0 < verbosity: print('died!')\n",
    "\n",
    "    for node_id in g.nodes():\n",
    "        g.nodes[node_id]['touched'] = 0\n",
    "        \n",
    "    return num_infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_infection(G, 0, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_map = {'susceptible': 0.0, 'recovered': 0.3, 'infected': 0.6, 'dead': 1.0}\n",
    "values = [val_map.get(G.nodes[node_id]['state'], 0.5) for node_id in G.nodes()]\n",
    "print(values)\n",
    "nx.draw(G, pos, cmap=plt.get_cmap('bwr'), node_color=values, with_labels=True, font_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(propagate_infection(G, 4, 1, 0.1, 0.01, verbosity=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_map = {'susceptible': 0.0, 'recovered': 0.3, 'infected': 0.6, 'dead': 1.0}\n",
    "values = [val_map.get(G.nodes[node_id]['state'], 0.5) for node_id in G.nodes()]\n",
    "print(values)\n",
    "nx.draw(G, pos, cmap=plt.get_cmap('bwr'), node_color=values, with_labels=True, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `matplotlib`'s `tab20b` or `Paired` [colormaps](https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html), which are the following:\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"ipynb.images/tab20b.png\" width=600 />\n",
    "</center>\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"ipynb.images/paired.png\" width=600 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(propagate_infection(G, 4, 1, 0.1, 0.01))\n",
    "values = [val_map.get(G.nodes[node_id]['state'], 0.5) for node_id in G.nodes()]\n",
    "print(values)\n",
    "nx.draw(G, pos, cmap=plt.get_cmap('tab20b'), node_color=values, with_labels=True, font_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#initialise the graph and settings\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "#ax.patch.set_alpha(0.1)\n",
    "plt.ion()\n",
    "\n",
    "# reseed graph\n",
    "seed_infection(G, 0)\n",
    "\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "#iterate - plot, erase\n",
    "for i in range(0, 50):\n",
    "    #print i\n",
    "    ax.clear() # - Clear\n",
    "\n",
    "    propagate_infection(G, 4, 1, 0.1, 0.01)\n",
    "    values = [val_map.get(G.nodes[node_id]['state'], 0.5) for node_id in G.nodes()]\n",
    "    #print(values)\n",
    "    nx.draw(G, pos, cmap=plt.get_cmap('Paired'), node_color=values, with_labels=True, font_color='white')\n",
    "    \n",
    "    #ax.patch.set_alpha(0.1)\n",
    "    fig.canvas.draw()   # draw\n",
    "    time.sleep(1.0)    #sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "Now write a function that tallies up total dead for each graph network type, and run some simulations to plot number of dead versus infection parameters (specifically, beta, r, and f). What social distancing measures would you enact in your country to safeguard the population?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
