{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Sci Engineering Methods and Tools, Week 4 Lecture 2</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 29 January 2020, with material from Cam Davidson-Pilon</div>\n",
    "\n",
    "At the end of this lecture, you should a good understanding of probability distributions, how to estimate probabilities for different outcomes and sample spaces, and how to use Bayes' theorem to answer typical interview questions involving probabilities, and become curious about Formula 1 racing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "* * * \n",
    "# Introduction to Probability Distributions\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"http://statistics.wdfiles.com/local--files/ch6/binomial.png\" width=\"400\" />\n",
    "Binomial\n",
    "</center>\n",
    "\n",
    "So far, we have made the assumption that every outcome in a sample space (urn) is ***equally likely***: Same probability to select White ball \\#1 as Red ball \\#5. \n",
    "\n",
    ">**Recall**: A probability is a **fraction** where the numerator is sum of all *favorable* outcomes, and the denominator the sum of all *possible* outcomes.\n",
    "\n",
    "In real life, we often get outcomes that are not **equiprobable**. Foe example, White ball versus Red ball. For another example, the probability of a child being a girl is not exactly 1/2, and the probability is slightly different for a second child. \n",
    "\n",
    "An [article](http://people.kzoo.edu/barth/math105/moreboys.pdf) (good Data Science article, you should read it) gives the following *counts* for two-child families in Denmark, where `GB` means a family where the first child is a girl and the second a boy:\n",
    "\n",
    "    GG: 121801    GB: 126840\n",
    "    BG: 127123    BB: 135138\n",
    "    \n",
    "Because of this fact (not all urns yield Blue/Red/White *numbered* balls with equiprobable chances), we need to introduce three more definitions:\n",
    "\n",
    "* [Frequency](https://en.wikipedia.org/wiki/Frequency_%28statistics%29): a number describing how often an outcome occurs. Can be a count like 121801, or a ratio like 0.515.\n",
    "\n",
    "* [Distribution](http://mathworld.wolfram.com/StatisticalDistribution.html): A mapping from outcome to frequency for each possible outcome in a sample space. \n",
    "\n",
    "* [Probability Distribution](https://en.wikipedia.org/wiki/Probability_distribution): The distribution above, which has been *normalized* so that the sum of the frequencies is 1.\n",
    "\n",
    "Here is an example of a ***super-popular*** probability distribution:\n",
    "* The binomial distribution is frequently used to model the number of successes in a sample of size n drawn with replacement from a population of size N. It is parametrized by p and is the discrete probability distribution of the number of `yes`es in a sequence of n independent experiments *with replacement*, each asking a `yes/no` question, and each with its own boolean-valued outcome: a random variable containing a single bit of information: `yes` (with probability p) or `no` (with probability q = 1 − p)\n",
    "\n",
    "* A single `yes/no` experiment is also called a *Bernoulli trial* or *Bernoulli experiment* and a sequence of outcomes is called a *Bernoulli process*\n",
    "\n",
    "* For a single trial, i.e., n = 1, the binomial distribution is a Bernoulli distribution. \n",
    "\n",
    "So now we need to modify our awesome probability counting `p()` function (which takes each event as **equiprobable**) to take this miserable fact into account. Essentially, it's as if each *numbered ball* comes with its *own* probability of being picked. So we will need to use probability **dictionaries**.\n",
    "\n",
    "<center>\n",
    "    <img src=\"ipynb.images/miserable.png\" width=300 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x270 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first, let's plot a few binomial distributions\n",
    "# n and p are exactly as defined above\n",
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n_values = [20, 25, 40]\n",
    "p_values = [0.2, 0.6, 0.6]\n",
    "x = np.arange(0, 50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3.75))\n",
    "\n",
    "for (n, p) in zip(n_values, p_values):\n",
    "    # create a binomial distribution\n",
    "    dist = binom(n, p)\n",
    "\n",
    "    plt.plot(x, dist.pmf(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for that, we need to digress a bit..\n",
    "\n",
    "In Python, `*args` and `**kwargs` is a common idiom to allow ***arbitrary number of arguments*** to functions. `*args` will give you all function parameters as a tuple, `**kwargs` will give you all keyword arguments (except those corresponding to a formal parameter) as a dictionary:\n",
    "```python\n",
    "def foo(*args):\n",
    "    for a in args:\n",
    "    print a\n",
    "        \n",
    "def bar(**kwargs):\n",
    "    for a in kwargs:\n",
    "        print a, kwargs[a]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say we want to create a higher-order function that takes as input some function $f$ and returns a new function that for any input returns *twice* the value of $f$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubler(f):\n",
    "  def g(x):\n",
    "    return 2 * f(x)\n",
    "  return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works in most cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "def f_plus_1(x):\n",
    "  return x + 1;\n",
    "\n",
    "g = doubler(f_plus_1)\n",
    "print(g(3))  # 8 = (3 + 1) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "g() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-acbdc6e5f4bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoubler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#TypeError!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: g() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "def sum(x, y):\n",
    "  return x + y;\n",
    "\n",
    "g = doubler(sum)\n",
    "print(g(1,2)) #TypeError!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oopsie!\n",
    "\n",
    "What we need is a way to specify a function that takes *arbitrary arguments*. This is where Python's `*args` and `**kwargs` come into play:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unnamed args:  (1, 2, 3)\n",
      "keyword args:  {'key1': 'NU', 'key2': 'rocks!'}\n"
     ]
    }
   ],
   "source": [
    "def magic(*args, **kwargs):\n",
    "  print (\"unnamed args: \", args)\n",
    "  print (\"keyword args: \", kwargs)\n",
    "magic(1, 2, 3, key1 = 'NU', key2 = 'rocks!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/magic.png\" width=300 />**Ohhhhhhhhhhhh**</a><br>Ni zheng bing!\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "args is a `tuple` of its unnamed arguments and kwargs is a `dictionary` of its named arguments. So now we can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doublerr(f):\n",
    "  \"\"\"works no matter the inputs\"\"\"\n",
    "  def g(*args, **kwargs):\n",
    "    \"\"\"pass all arguments to f\"\"\"\n",
    "    return 2 * f(*args, **kwargs)\n",
    "  return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "g = doublerr(sum)\n",
    "print(g(1, 2))  # 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now are ready to define **Probabiluty distributions** in python!\n",
    "\n",
    "We define `ProbDist` to take the same kinds of arguments that dict does: either a **mapping** (from item to its probability) or a **set** of (key, val) pairs, and/or optional keyword arguments (because each ball in the urn is *special* now: it has its *own* probability of being picked). \n",
    "\n",
    ">**A dose of reality**: It's like all boys/girls are not equal! You will not just pick any boy/girl to be your girl/boyfriend! There are some that have a *much higher chance* of being picked by you (related to *your* taste)!\n",
    "\n",
    "This is the first time (in class), that we will define a Python `class`, instead of a Python **function/lambda**. That is why we will define its **constructor** `__init__()`. We assume `self` (`this` in Python) is composed of a set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class ProbDist(dict):\n",
    "    \"\"\"A Probability Distribution; an {outcome: probability} mapping.\"\"\"\n",
    "    def __init__(self, mapping=(), **kwargs):\n",
    "        self.update(mapping, **kwargs)\n",
    "        # Make probabilities sum to 1.0; assert no negative probabilities\n",
    "        total = sum(self.values())\n",
    "        for outcome in self:\n",
    "            self[outcome] = self[outcome] / total\n",
    "            assert self[outcome] >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We also need to modify the functions `p` and `such_that` to accept either a sample space as we had previously, or a probability distribution as the second argument `space`. \n",
    "\n",
    ">**Oh-oh**: Now we need to branch out on the ***2nd argument** of function `p`!\n",
    "\n",
    "If we have a probability distribution, instead of *counting* each possible outcome equiprobably and thus just summing up `1`s (numerator: sum of all *favorable* outcomes, denominator: sum of all *possible* outcomes), we need to sum up the different discrete probabilities of each possible outcome: `sum(space[o] for o in space if o in event)`. \n",
    "\n",
    "We also need to modify `such_that()`, which is the set of all outcomes of our sample space for which the predicate (first) argument is `True`, so that its second argument can also be a `ProbDist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def p(event, space): \n",
    "    \"\"\"The probability of an event, given a sample space of equiprobable outcomes. \n",
    "    event: a collection of outcomes, or a predicate that is true of outcomes in the event. \n",
    "    space: a set of outcomes or a probability distribution of {outcome: frequency} pairs.\"\"\"\n",
    "    if is_predicate(event):\n",
    "        event = such_that(event, space)\n",
    "    if isinstance(space, ProbDist):\n",
    "        return sum(space[o] for o in space if o in event)\n",
    "    else:\n",
    "        return Fraction(len(event & space), len(space))\n",
    "\n",
    "is_predicate = callable\n",
    "\n",
    "def such_that(predicate, space): \n",
    "    \"\"\"The outcomes in the sample pace for which the predicate is true.\n",
    "    If space is a set, return a subset {outcome,...} with outcomes where predicate(element) is true;\n",
    "    if space is a ProbDist, return a ProbDist {outcome: frequency,...} with outcomes where predicate(element) is true.\"\"\"\n",
    "    if isinstance(space, ProbDist):\n",
    "        return ProbDist({o:space[o] for o in space if predicate(o)})\n",
    "    else:\n",
    "        return {o for o in space if predicate(o)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now we can finally take on the Danes!\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/Danes.png\" width=300 />\n",
    "</center>\n",
    "\n",
    "Here is the probability distribution for Danish two-child families as a dictionary describing the probability of each possible outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-c2fa5af13dae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m DK = ProbDist(GG=121801, GB=126840,\n\u001b[1;32m----> 2\u001b[1;33m               BG=127123, BB=135138)\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mDK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-ccc480d4464f>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mapping, **kwargs)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# Make probabilities sum to 1.0; assert no negative probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0moutcome\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutcome\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sum() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "DK = ProbDist(GG=121801, GB=126840,\n",
    "              BG=127123, BB=135138)\n",
    "DK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's write some useful predicates (lambdas):\n",
    "```python\n",
    "def first_girl(outcome):  return outcome[0] == 'G'\n",
    "def first_boy(outcome):   return outcome[0] == 'B'\n",
    "def second_girl(outcome): return outcome[1] == 'G'\n",
    "def second_boy(outcome):  return outcome[1] == 'B'\n",
    "def two_girls(outcome):   return outcome    == 'GG'\n",
    "```\n",
    "Using these predicates, answer the following questions:\n",
    "\n",
    "* What's the probability for a girl, and is it higher or lower for a second girl?\n",
    "* Is the sex of the second child more likely or less likely to be the same as the first child?\n",
    "\n",
    "*Hint:* You will leverage `p(first_girl, DK)`, `p(second_girl, DK)`, `p(second_girl, such_that(first_girl, DK))`, and `p(second_girl, such_that(first_boy, DK))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def first_girl(outcome):  return outcome[0] == 'G'\n",
    "def first_boy(outcome):   return outcome[0] == 'B'\n",
    "def second_girl(outcome): return outcome[1] == 'G'\n",
    "def second_boy(outcome):  return outcome[1] == 'B'\n",
    "def two_girls(outcome):   return outcome    == 'GG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(first_girl, DK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(second_girl, DK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above says that the probability of a girl is somewhere between 48% and 49%, but that it is slightly different between the first or second child.\n",
    "\n",
    "Now answer the question as to whether the sex of the second child is *more likely* or *less likely* to be the same as the first child, by evaluating first:\n",
    "\n",
    "- The probability of a second girl given that the first child was a girl (a joint probability)\n",
    "- The probability of a second girl given that the first child was a boy (a joint probability)\n",
    "- The probability of a second boy given that the first child was a boy (a joint probability)\n",
    "- The probability of a second boy given that the first child was a girl (a joint probability)\n",
    "\n",
    "The average of the first two probabilities above represents the probability of a second girl, a [**marginal probability**](https://en.wikipedia.org/wiki/Marginal_distribution) in our problem.\n",
    "\n",
    "The avergage of the last two probabilities above represents the probability of a second boy, a **marginal probability** in our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above says that the sex of the second child is more likely to be the same as the first child, by about 1/2 a percentage point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You should find that the probability of a girl is somewhere between 48% and 49%, but slightly different between the first or second child, and that the sex of the second child is more likely to be the same as the first child, by about 1/2 a percentage point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# 6. M&Ms and Bayes\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/9/97/M%26M_spokescandies.jpeg\" />\n",
    "</center>\n",
    "\n",
    "Here's another classic urn problem (or \"bag\" problem) [from](http://allendowney.blogspot.com/2011/10/my-favorite-bayess-theorem-problems.html) prolific Python/Probability author [Allen Downey ](http://allendowney.blogspot.com/), which also happens to be a classic interview question:\n",
    "\n",
    "> The blue M&M was introduced in 1995.  Before then, the color mix in a bag of plain M&Ms was (30% Brown, 20% Yellow, 20% Red, 10% Green, 10% Orange, 10% Tan).  Afterward it was (24% Blue , 20% Green, 16% Orange, 14% Yellow, 13% Red, 13% Brown). \n",
    "A friend of mine has two bags of M&Ms, and he tells me that one is from 1994 and one from 1996.  He won't tell me which is which, but he gives me one M&M from each bag.  One is yellow and one is green.  What is the probability that the yellow M&M came from the 1994 bag? Well, the old M&M bags' yellow count was higher, so it must be higher, right? But how to count?\n",
    "\n",
    "To solve this problem, we'll first represent probability distributions for each bag: `bag94` and `bag96`, by using `ProbDist` and passing in dictionaries for each year:\n",
    "```python\n",
    "bag94 = ProbDist(brown=30, yellow=20, red=20, green=10, orange=10, tan=10)\n",
    "bag96 = ProbDist(...)  #fill this in, please\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bag94 = ProbDist(brown=30, yellow=20, red=20, green=10, orange=10, tan=10)\n",
    "bag96 = ProbDist(blue=24, green=20, orange=16, yellow=14, red=13, brown=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, define `MM` as the *joint* distribution 94-96&mdash;the sample space for picking *one* M&M from *each* bag. The outcome `'yellow green'` means that a yellow M&M was selected from the 1994 bag and a green one from the 1996 bag. We will use a *set comprehension*.\n",
    "\n",
    "Uhhhh... What do we use for sets again? Is it `[`, or `(`, or `{`?\n",
    "\n",
    "To note:\n",
    "* We are using a python *set* because we care about dictionaries, and dictionary keys are unique\n",
    "* You can also think in terms of JSON objects\n",
    "\n",
    "```python\n",
    "def joint(A, B, sep=''):\n",
    "    \"\"\"The joint distribution of two independent probability distributions. \n",
    "    Result is all entries of the form {a+sep+b: P(a)*P(b)}\"\"\"\n",
    "    return ProbDist({a + sep + b: A[a] * B[b]\n",
    "                    for ...\n",
    "                    for ...})\n",
    "\n",
    "MM = joint(bag94, bag96, ' ')\n",
    "MM\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def joint(A, B, sep=''):\n",
    "    \"\"\"The joint distribution of two independent probability distributions. \n",
    "    Result is all entries of the form {a+sep+b: P(a)*P(b)}\"\"\"\n",
    "    return ProbDist({a + sep + b: A[a] * B[b]\n",
    "                    for a ...\n",
    "                    for b ...})\n",
    "\n",
    "MM = joint(bag94, bag96, ' ')\n",
    "MM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's look at the \"One is yellow and one is green\" part:\n",
    "\n",
    "```python\n",
    "def yellow_and_green(outcome): return 'yellow' in outcome and 'green' in outcome\n",
    "\n",
    "such_that(...) # fill this in\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def yellow_and_green(outcome): return 'yellow' in outcome and 'green' in outcome\n",
    "such_that(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now we can answer the question: given that we got a yellow and a green (but don't know which comes from which bag), what is the probability that the yellow came from the 1994 bag?\n",
    "\n",
    "```python\n",
    "def yellow94(outcome): return ...\n",
    "\n",
    "p(yellow94, such_that(...)) # fill this in\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def yellow94(outcome): return outcome.startswith('yellow')\n",
    "\n",
    "p(yellow94, such_that(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "So there is a 74% chance that the yellow comes from the 1994 bag. We were *right* about our hunch :-)\n",
    "\n",
    "Answering this question was straightforward: just like all the other probability problems, we simply create a sample space, and use `p` to pick out the probability of the event in question, given what we know about the outcome. This is the 'mechanistic' way of obtaining our answer.\n",
    "\n",
    "We can *also* solve it using *Bayes' Theorem*, and this is as good as any's introduction to naive Bayes theory: We are asked about the probability of an event (M&M94 --> M&M96) given the evidence (M&M94 is yellow, M&M96 green), which is not immediately available. However the probability of the evidence, given the event is readily available!  \n",
    "\n",
    "Before we see the colors of the M&Ms, there are two hypotheses, `A` and `B`, both with equal probability:\n",
    "\n",
    "    A: first M&M from 94 bag, second from 96 bag\n",
    "    B: first M&M from 96 bag, second from 94 bag\n",
    "    P(A) = P(B) = 0.5\n",
    "    \n",
    "Then we get some evidence:\n",
    "    \n",
    "    E: first M&M yellow, second green\n",
    "    \n",
    "We want to know the probability of hypothesis `A`, given the evidence:\n",
    "    \n",
    "    P(A | E)\n",
    "    \n",
    "That's not easy to calculate (except by enumerating the sample space, which is what we did above). But Bayes Theorem says:\n",
    "    \n",
    "    P(A | E) = P(E | A) * P(A) / P(E)\n",
    "    \n",
    "The quantities on the *right-hand-side* are easier to calculate:\n",
    "    \n",
    "    P(E | A) = 20/100 * 20/100 = 0.04\n",
    "    P(E | B) = 10/100 * 14/100 = 0.014\n",
    "    P(A)     = 0.5\n",
    "    P(B)     = 0.5\n",
    "    P(E)     = P(E | A) * P(A) + P(E | B) * P(B) \n",
    "             = 0.04     * 0.5  + 0.014    * 0.5   =   0.027\n",
    "             \n",
    "Where did the probability of the evidence P(E) formula come from?\n",
    "\n",
    "There are two possibilities of getting the evidence: A and B, a *union* and so we sum their probabilities. The joint probability of the evidence *and* case A is a succession or *intersection*, so it must be a product of their probabilities: P(E|A).P(A). Likewise for the case B: P(E|B).P(B) \n",
    "    \n",
    "And so we can get a final answer:\n",
    "    \n",
    "    P(A | E) = P(E | A) * P(A) / P(E) \n",
    "             = 0.04     * 0.5  / 0.027 \n",
    "             = 0.7407407407\n",
    "             \n",
    "Bayes Theorem allows you to do less calculation at the cost of more algebra; that is a great trade-off if you are working with pencil and paper (like in interview situations). Enumerating the state space allows you to do less algebra at the cost of more calculation; often a good trade-off if you have a computer. But regardless of the approach you use, it is important to understand Bayes theorem and how it works.\n",
    "\n",
    "Bayes' theorem will be our introduction to more advanced statistics, which we'll cover *next* week!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data? Big Deal..\n",
    "\n",
    "So far, we have talked of an *outcome* as being a single state of the world. But it can be useful to break that state of the world down into many components. We call these components **random variables**. For example, when we consider an experiment in which we roll *two* dice and observe their sum, we could model the situation with *two* random variables, one for each die (our representation of outcomes has been doing that implicitly all along, when we concatenate two parts of a string, but the concept of a random variable makes it official.)\n",
    "\n",
    "Remember [this](https://www.mathsisfun.com/data/quincunx.html) experiment?\n",
    "\n",
    "The **Central Limit Theorem** states that if you have a collection of random variables and sum them up, then the *larger* the collection, the *closer* the sum will be to a *normal distribution* (also called a *Gaussian distribution* or a *bell-shaped curve*). This illustrates why Data Science with **Big Data** is not really a challenge at all (other than how to store and compute with data that is larger than the RAM on your laptop)! If you have tons of data, then frequentist and Bayesian statistics coincide, there is little doubt about outcomes, and it is clear which outcome to place your bets on.\n",
    "\n",
    "The challenge is with **Small Data**, where there is doubt and you have no idea of the pdf, and you have to painstakingly  build a model with parameters, and refine your parameters so the model fits the data.\n",
    "\n",
    "Why do accidents happen in autonomous vehicles when it snows, at dusk, when the moon is behind a traffic light, and a pedestrian is crossing the street on a red light? Precisely because we don't have Big Data about that use case, and the autonomous car has **no idea what to do**! Uber needs *you* to program it for the Small DAta cases. Big Data is piece of cake!\n",
    "\n",
    "This is a good time to introduce the concept of a **histogram**, which is essentially a probability density function that we get from data collection or from analytic curves. If we have the 2D function `f(x,y)`, we can estimate the discretized probability density function (pdf) of `f` by computing how many values of `f` fall into specific bins with prespecified values of y.\n",
    "\n",
    "Plot the pdf of the following graph:\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/graph.png\" width=200 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celtics\n",
    "\n",
    "As another example, let's take 5 random variables reprsenting the per-game scores of the 5 Celtics starters for the 2018 season (Jayson Tatum or JT, Jaylen Brown or JB, Terry Rozier or TR, Al Horford or AL, and Aron Baynes or AB), and then sum them together to form the team score. The scores here are imaginary to introduce statistical function `gauss`, `triangular`, `vonmisesvariate`, and `uniform`. For the real season scores of this exciting and ultimately deflating season, visit [here](http://www.nba.com/celtics/stats?sort=PTS). Each random variable/player is represented as a probability distribution function; calling the function returns a single sample from the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import gauss, triangular, choice, vonmisesvariate, uniform\n",
    "\n",
    "def JT(): return posint(gauss(15.1, 3) + 3 * triangular(1, 4, 13)) # 30.1\n",
    "def JB(): return posint(gauss(10.2, 3) + 3 * triangular(1, 3.5, 9)) # 22.1\n",
    "def TR(): return posint(vonmisesvariate(30, 2) * 3.08) # 14.0\n",
    "def AH(): return posint(gauss(6.7, 1.5) if choice((True, False)) else gauss(16.7, 2.5)) # 11.7\n",
    "def AB(): return posint(triangular(5, 17, 25) + uniform(0, 30) + gauss(6, 3)) # 37.0\n",
    "\n",
    "def posint(x): \"Positive integer\"; return max(0, int(round(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a function to sample a random variable *k* times, show a histogram of the results, and return the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def repeated_hist(rv, bins=10, k=100000):\n",
    "    \"Repeat rv() k times and make a histogram of the results.\"\n",
    "    samples = [rv() for _ in range(k)]\n",
    "    plt.hist(samples, bins=bins)\n",
    "    return mean(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two top-scoring players, Jayson Tatum (JT) and Jaylen Brown (JB), have scoring distributions that are slightly skewed from normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_hist(JT, bins=range(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_hist(JB, bins=range(60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two players have bi-modal distributions; some games they score a lot, some games not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_hist(TR, bins=range(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_hist(AH, bins=range(60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fifth \"player\" (actually the sum of all the other players on the team, not really Aron Baymes, or they would have easily defeated the Cavaliers!) looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_hist(AB, bins=range(60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead, add more players to the Celtics, each with their own scoring distribution. Modify and use the below template:\n",
    "```python\n",
    "def XX(): return posint(gauss(15.1, 3) + 3 * triangular(1, 4, 13)) # 30.1\n",
    "```\n",
    "\n",
    "Add then in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the team score to be the sum of the five players, and look at the distribution. Don't forge to add your own players!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GSW(): return JT() + JB() + TR() + AH() + AB()  # + ... add your own players!\n",
    "\n",
    "repeated_hist(GSW, bins=range(70, 160, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough, this looks very much like a **normal distribution**! \n",
    "\n",
    "The Central Limit Theorem holds, and that is why the statistics of NBA teams are so *predictable*. \n",
    "\n",
    "When you have a lot of data, you have little doubt, and the Data Science is *easy*. Deep Learning ANNs are very good at building hypersurfaces that match all the state variables of past outcomes. When you are asked to predict new outcomes based on a partial subset of state variables (independent variables), machines just project the lower dimensional hypersurface onto the higher dimensional hypersurface (stored in very compact form) and fill in the missing dimensions in order to predict the dependent variables. \n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/manifold.jpg\" width=300 />\n",
    "</center>\n",
    "\n",
    "\n",
    "We saw just a few days ago how machines can even predict non-linear functions if we give them tons of data, but when the data is not enough, they *cannot* predict!\n",
    "\n",
    "So what do we do when we *don't have enough data*? Do we just give up? We'll see next week how **Bayesian statistics** come to the rescue, *when we have to deal with doubt*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion¶\n",
    "We've built a framework for estimating probabilities that will come in handy when you are asked to build data models. We *started playing* with **Bayes' theorem**, a *pillar* of data science, and we started learning how to answer typical Data Science interview questions, which you should *always* answer in python because you *will* run out of space on the whiteboard if you use squiggly brackets and other languages! \n",
    "\n",
    "Next week we move on to statistical modeling and inference. \n",
    "\n",
    "**Modeling** (one `l` or 2 `l`s? See [here](https://www.grammarly.com/blog/modeling-or-modelling/)) happens when data is scarce and precious and hard to obtain, for example in social sciences and settings where it is difficult to conduct large-scale controlled experiments. With small data it is important to quantify uncertainty and that’s precisely what Bayesian approaches are good at. **Inference** refers to how you learn parameters of your model (Markov Chain Monte Carlo, or MCMC, albeit computationally expensive, is one of the most important methods for statistical inference), which is especially important with Bayesian Machine Learning, where we can actually inquire with Machines why this or that action was undertaken.\n",
    "\n",
    "*Alexa, why did you lower the temperature in the bedroom?* **Because your wife told me that whenever you start snoring, John, colder tempreatures make you bundle up under the cover and you snore less**. \n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/echo.jpg\" width=200 />\n",
    "</center>\n",
    "\n",
    "Best advice for interviews: Be explicit about what the problem says, have the interviewer verify the working hypotheses, be methodical about defining the sample space, be careful in counting the number of outcomes in the numerator and denominator, and finally use Bayes' theorem (or 1 minus the negation) whenever possible because you will be doing calculations by hand on a whiteboard!\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/jobinterview.jpg\" width=400 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework for next week: Introduction to Data Science for Sports\n",
    "\n",
    "You will exercise your knowledge of probabilities and writing down logic with python.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "    <img src=\"ipynb.images/f1races.png\" width=800 />\n",
    "</center>\n",
    "\n",
    "Question 1.1 (20 points) There are a number of F1 races coming up: \n",
    "- Singapore GP: Date: Sun, Sep 22, 8:10 AM\n",
    "- Russian GP: Date: Sun, Sep 29, 7:10 AM\n",
    "- Japanese GP: Date: Sun, Oct 13, 1:10 AM\n",
    "- Mexican GP Date: Sun, Oct 13, 1:10 AM\n",
    "\n",
    "We are just before the Singaporean Grand Prix (this coming weekend) and the Russian Grand Prix the weekend after, as you can see [schedule](https://www.formula1.com/en/racing/2019.html). \n",
    "\n",
    "The 2019 driver standings are given [here](https://www.formula1.com/en/results.html/2019/drivers.html). Assume these standings for this weekend, even though they are final season standings. Given these standings (please do not use team standings given on the same Web site, use ***driver standings***), what is the Probability Distribution for each F1 driver to win the Singaporean Grand Prix? What is the Probability Distribution for each F1 driver to win *both* the Singaporean and Russian Grand Prix? What is the probability for Mercedes to win both races? What is the probability for Mercedes to win at least one race? Note that Mercedes, and each other racing team, has two drivers per race. Assume that Singaporean grand prix standings are not going to change driver standings by much, so you can use same standings for both races.\n",
    "\n",
    "Question 1.2 (30 points) If Mercedes wins the first race, what is the probability that Mercedes wins the next one? If Mercedes wins at least one of these two races, what is the probability Mercedes wins both races? How about Ferrari, Red Bull, and Renault?\n",
    "\n",
    "Question 1.3 (50 points) Mercedes wins at least one of these two races on a **rainy** day. What is the probability Mercedes wins both races, assuming races can be held on either rainy, sunny, cloudy, snowy or foggy days? Assume that rain, sun, clouds, snow, and fog are the *only possible weather conditions* on race tracks.\n",
    "\n",
    "You need to provide *proof* for your answers. `I think it's one in a million because Mercedes sucks and I like Ferrari a lot more` is not a good answer. Leverage the counting framework in this workbook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Use SingaporeanGrandPrix, or `SGP` to denote the Probability Distribution given by F1 driver wins. Write driver initials as keys and driver wins as values in a dictionary that you pass to our function `ProbDist`.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGP = ProbDist(\n",
    "    LH = 413,\n",
    "    VB = 326,\n",
    "    MV = 278,\n",
    "    ...)\n",
    "SGP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
