{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Science Eng Methods and Tools, Lecture 13 Day 2</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 8 April 2020</div>\n",
    "\n",
    "# Building ANNs with Conx\n",
    "\n",
    "In our last class we developed our own Artifical Neural Network (ANN), using feedfoward and backpropagation. There was a little bit of math involved. Thankfully, there are libraries to help with the math. Let's learn about a nice simple small one: `conx`.\n",
    "\n",
    "We're going to leverage `Conx` to build discriminative neural networks, learn correlations, and predict dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first do a `pip install conx` on an anaconda terminal. If you can't, do a `!pip install conx` in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "ConX, version 3.7.10\n"
     ]
    }
   ],
   "source": [
    "import conx as cx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like `PyMC3`, it has a `Theano` dependency. \n",
    "\n",
    "`Conx` has some classical built-in datasets that you can directly leverage for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cifar10',\n",
       " 'cifar100',\n",
       " 'cmu_faces_full_size',\n",
       " 'cmu_faces_half_size',\n",
       " 'cmu_faces_quarter_size',\n",
       " 'colors',\n",
       " 'figure_ground_a',\n",
       " 'fingers',\n",
       " 'gridfonts',\n",
       " 'mnist',\n",
       " 'mnist_h5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx.Dataset.datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do not** try the below, it will take too long: 10 minutes or so to download the dataset (I know, I *tried*). Try it at home, if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Dataset**: Unnamed Dataset\n",
       "\n",
       "**Information**:\n",
       "   * name    : None\n",
       "   * length  : 70000\n",
       "\n",
       "**Input Summary**:\n",
       "   * shape  : (28, 28, 1)\n",
       "   * range  : (0.0, 1.0)\n",
       "\n",
       "**Target Summary**:\n",
       "   * shape  : (10,)\n",
       "   * range  : (0, 1)\n",
       "\n"
      ],
      "text/plain": [
       "**Dataset**: Unnamed Dataset\n",
       "\n",
       "**Information**:\n",
       "   * name    : None\n",
       "   * length  : 70000\n",
       "\n",
       "**Input Summary**:\n",
       "   * shape  : (28, 28, 1)\n",
       "   * range  : (0.0, 1.0)\n",
       "\n",
       "**Target Summary**:\n",
       "   * shape  : (10,)\n",
       "   * range  : (0, 1)\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = cx.Dataset.get('mnist')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2D2 on two legs\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"ipynb.images/r2d22.png\" width=300 />\n",
    "</center>\n",
    "\n",
    "Did you know R2D2 can raise one of its legs and actually walk on two legs?\n",
    "\n",
    "Notice the shape of our data below: Inputs are clearly separated from the labels. We sense inputs from R2D2's two legs and learn whether to go forward or backward, just like in our previous lab (how did icome up with the data? It's a simple XOR dataset!).\n",
    "\n",
    "We will build a network consisting of an input layer consisting of two nodes (for the two legs), a hidden layer consisting of 5 nodes this time instead of 4, and an output layer consisting again of one node. So, how many weights in total? That's the **complexity** of your network.\n",
    "\n",
    "The node transfer function will be our good old friend the [sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function). \n",
    "\n",
    "We load the data. We then compile our network the same way we compile a classic program. That sets up the matrices that will contain the weights and the adjacency matrix that will define our network graph. Let's see how to do this with `conx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [[[0, 0], [0]],\n",
    "           [[0, 1], [1]],\n",
    "           [[1, 0], [1]],\n",
    "           [[1, 1], [0]]]\n",
    "\n",
    "net = cx.Network(\"R2D2\", 2, 5, 1, activation=\"sigmoid\")\n",
    "net.dataset.load(dataset)\n",
    "net.compile(error='mean_squared_error', optimizer=\"sgd\", lr=0.3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then ask for a summary of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "R2D2 Dataset:\n",
      "Patterns    Shape                 Range                         \n",
      "=================================================================\n",
      "inputs      (2,)                  (0.0, 1.0)                    \n",
      "targets     (1,)                  (0.0, 1.0)                    \n",
      "=================================================================\n",
      "Total patterns: 4\n",
      "   Training patterns: 4\n",
      "   Testing patterns: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.dataset.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For kicks, let's propagate a signal down our network and examine its *untrained* output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6311073303222656]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.propagate([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means walk forward, R2D2!\n",
    "\n",
    "We can even propagate *weird* (unexpected) signals (both R2D2 feet only *slightly* touching the ground?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5888906717300415]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.propagate([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm.. probably backwards, R2D2!\n",
    "\n",
    "We can sample the entire input space for the two input units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Output Activation')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "z = np.zeros((100, 100))\n",
    "\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        z[x][y] = net.propagate(input=[x/100, y/100])[0]\n",
    "\n",
    "plt.imshow(z, cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.xlabel(\"input 1\")\n",
    "plt.ylabel(\"input 2\")\n",
    "plt.title(\"Output Activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-c1081ee9b80b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-c1081ee9b80b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    We can even get a 照片 of our network, to verify we got it right.\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "We can even get a 照片 of our network, to verify we got it right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.picture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have ourselves two input nodes, 5 hidden nodes, and one output node!\n",
    "\n",
    "Let's *learn*! Let's say 2000 epochs (timesteps), with the hyperparameters specified below. Note that we are very\n",
    "demanding on our little network! We demand an accuracy of 100%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train(2000, report_rate=10, accuracy=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see the network total error and accuracy as it trains.\n",
    "\n",
    "The cell below is from an older API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.test(show=True)\n",
    "dataset = [[[0, 0], [0]],\n",
    "           [[0, 1], [1]],\n",
    "           [[1, 0], [1]],\n",
    "           [[1, 1], [0]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's propagate the same signals as before on our *trained* network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.propagate([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now , it looks like R2D2 is confident enough to walk *forward* when it's two feet are only half-touching the ground!\n",
    "\n",
    "And how about the training inputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = [[[0, 0], [0]],\n",
    "#           [[0, 1], [1]],\n",
    "#           [[1, 0], [1]],\n",
    "#           [[1, 1], [0]]]\n",
    "\n",
    "net.propagate([0, 0]), net.propagate([0, 1]), net.propagate([1, 0]), net.propagate([1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/allright.gif width = 400 />\n",
    "</center>\n",
    "\n",
    "Allright allright allright! This is *fun*, let's build a more complicated network. Let's be more *explicit* about the layers.\n",
    "\n",
    "## Example \\#2\n",
    "\n",
    "What network architecture is this below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = cx.Network(\"XOR2 Network\")\n",
    "\n",
    "net2.add(cx.Layer(\"input1\", 1),\n",
    "         cx.Layer(\"input2\", 1),\n",
    "         cx.Layer(\"hidden1\", 10, activation=\"sigmoid\"),\n",
    "         cx.Layer(\"hidden2\", 10, activation=\"sigmoid\"),\n",
    "         cx.Layer(\"shared-hidden\", 5, activation=\"sigmoid\"),\n",
    "         cx.Layer(\"output1\", 1, activation=\"sigmoid\"),\n",
    "         cx.Layer(\"output2\", 1, activation=\"sigmoid\"))\n",
    "\n",
    "net2.connect(\"input1\", \"hidden1\")\n",
    "net2.connect(\"input2\", \"hidden2\")\n",
    "net2.connect(\"hidden1\", \"shared-hidden\")\n",
    "net2.connect(\"hidden2\", \"shared-hidden\")\n",
    "net2.connect(\"shared-hidden\", \"output1\")\n",
    "net2.connect(\"shared-hidden\", \"output2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compile our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.compile(loss='mean_squared_error', optimizer='SGD', lr=0.3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's picture it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.picture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, two inputs, each going to its own hidden layer of 10 neurons, then to a shared hidden layer of 5 neurons, followed by an output layer of ywo neurons.\n",
    "Let's propagate a signal into the *untrained* network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.propagate([[1], [1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a new dataset with the following inputs and desired outputs (labels).\n",
    "\n",
    "We essentially just unfold our original label into 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XOR2 = [\n",
    "    ([[0],[0]], [[0],[0]]),\n",
    "    ([[0],[1]], [[1],[1]]),\n",
    "    ([[1],[0]], [[1],[1]]),\n",
    "    ([[1],[1]], [[0],[0]])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.dataset.load(XOR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, you can get the weight of any layer at any time. These are the *untrained* weights of the `hidden2` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.get_weights(\"hidden2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's *learn* our labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2.train(epochs=2000, accuracy=1.0, report_rate=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see it *took us some time* to learn. There was even a period of despair, where we werent; learning *anything*. But eventually, we converged!\n",
    "\n",
    "We can even learn *by batches*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "net2.reset()\n",
    "for i in range(20):\n",
    "    (epoch_count, results) = net2.train(epochs=100, verbose=0, report_rate=25)\n",
    "    for index in range(4):\n",
    "        net2.propagate(XOR2[index][0])\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example \\#3\n",
    "\n",
    "A dataset is a list of (input, target) pairs that can be further split into training and testing lists. We can build this dataset quite artificially, say with random numbers, or we can even build it with *mathematical transformations*.\n",
    "\n",
    "Let's do a transformation. Let's build a network that will compute whether the number of 1's (*set* bits) in a set of 5 bits is **odd**. We will use a 5-10-1 network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conx as cx\n",
    "\n",
    "net = cx.Network(\"Odd Network\")\n",
    "net.add(cx.Layer(\"input\", 5))\n",
    "net.add(cx.Layer(\"hidden\", 10, activation=\"relu\"))\n",
    "net.add(cx.Layer(\"output\", 1, activation=\"sigmoid\"))\n",
    "net.connect()\n",
    "net.compile(error=\"mse\", optimizer=\"adam\")\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of (input, target) pairs\n",
    "\n",
    "The most straightforward method of loading input and target vectors to train on is to use a list of `(input, target)` pairs.\n",
    "\n",
    "Let's define a function that takes a number and returns its bitwise representation, using a list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a number and turn it into a list of bits (most significant first).\n",
    "def num2bin(i, bits=5):\n",
    "    return [int(s) for s in ((\"0\" * bits) + bin(i)[2:])[-bits:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "num2bin(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the list of `(iput, target)` pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = []\n",
    "\n",
    "for i in range(2 ** 5):\n",
    "    inputs = num2bin(i)\n",
    "    targets = [int(sum(inputs) % 2 == 1.0)]\n",
    "    patterns.append((inputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load that data onto our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.dataset.load(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.picture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train(epochs=5000, accuracy=.75, tolerance=.2, report_rate=100, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.evaluate(tolerance=.2, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example \\#4\n",
    "\n",
    "Now let's work with a wines dataset and build and train a network to become a wine *connaisseur*!\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src =ipynb.images/wine-connoisseur.jpg width = 500 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "wines = pd.read_csv('data/winequality-red.csv',header=None)\n",
    "wines.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Labels` is what we're trying to *predict*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = wines.loc[:,11].values\n",
    "labels[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many distinct categories? Let's use a python `set`, which removes duplicates, to look at the diversity of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the title (`quality`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = wines.loc[1:, 11].values.astype(float)\n",
    "labels[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simplify our labels by having them start at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = map(lambda x: x - 3, labels)\n",
    "labels2 = list(labels2)\n",
    "set(labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the independent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = wines.loc[1:,:10].values.astype(float)\n",
    "np.shape(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build our network with one hidden layer of 14 neurons. The input layer is composed of neurons numbering the number of independent variables: 11. \n",
    "And the output layer is composed of neurons numbering the range of our categorical label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from calysto.ai.conx import *\n",
    "\n",
    "#wine_net = Network()\n",
    "#wine_net.addLayers(11, 14, 6) #input -11, hidden-14, output-5\n",
    "#wine_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conx as cx\n",
    "\n",
    "wine = cx.Network(\"Wine Network\")\n",
    "wine.add(cx.Layer(\"input\", 11))\n",
    "wine.add(cx.Layer(\"hidden\", 14, activation=\"relu\"))\n",
    "wine.add(cx.Layer(\"output\", 6, activation=\"sigmoid\"))\n",
    "wine.connect()\n",
    "wine.compile(error=\"mse\", optimizer=\"adam\")\n",
    "wine.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.picture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.propagate(input= [6.9, 0.605, 0.12, 10.7, 0.073, 40, 83, 0.9993, 3.45, 0.52, 9.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how an untrained network works on the wine problem, let's propagate the input activations for each input pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train[:10]:\n",
    "    for pattern in [item]:\n",
    "        print(pattern, wine.propagate(input=pattern), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the output consists of 6 distinct cateogries, the classical way of handling this is with ***6 output nodes***.  \n",
    "\n",
    "So we need a 6-dimensional vector or outputs. So we ***one-hot encode*** the output variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding takes a **categorical variable** and re-encodes it as a **binary variable** in multiple dimensions. \n",
    "You'll see this often in Machine Learning algorithms, and we saw this together in our weather dataset that we used with\n",
    "our random forest modeling in the beginning of the semester!\n",
    "\n",
    "| week |\n",
    "|------|\n",
    "| Mon  |\n",
    "| Tue  |\n",
    "| Wed  |\n",
    "| Thu  |\n",
    "| Fri  |\n",
    "\n",
    "and converts it into:\n",
    "\n",
    "| Mon | Tue | Wed | Thu | Fri |\n",
    "|-----|-----|-----|-----|-----|\n",
    "| 1   | 0   | 0   | 0   | 0   |\n",
    "| 0   | 1   | 0   | 0   | 0   |\n",
    "| 0   | 0   | 1   | 0   | 0   |\n",
    "| 0   | 0   | 0   | 1   | 0   |\n",
    "| 0   | 0   | 0   | 0   | 1   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's one-hot encode using `pandas`, and verify we did ok by adding the categorical variable as a column right next to the encoding for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "labels3 = pd.get_dummies(labels2)\n",
    "view = labels3.head(20)\n",
    "view['val'] = labels2[:20]\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what our labels look like (5-dimensional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels3.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what our training data looks like (11-dimensional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list((labels3.values)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build our dataset as a list of `(input, label)` pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(train, labels3.values))\n",
    "patterns = []\n",
    "\n",
    "for i in range(0, len(train)):\n",
    "    #inputs = list(np.vectorize(int)(train[i]))\n",
    "    inputs = list(train[i])\n",
    "    targets = list((labels3.values)[i])\n",
    "    patterns.append((inputs, targets))\n",
    "    \n",
    "patterns[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wine.setInputs(train)\n",
    "#wine.setOutputs(labels2)\n",
    "wine.dataset.load(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.reset()\n",
    "wine.train(epochs=5000, accuracy=.75, tolerance=.2, report_rate=100, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh oh... We don't seem to converge! Looks like one hidden layer *is not enough*!\n",
    "\n",
    "Let's try another network architecture with an extra hidden layer. So let's reduce the number of neurons in the old \n",
    "single hidden layer, to two layers, with 9 neurons for the first layer and 7 for the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine2 = cx.Network(\"Wine Network Number 2\")\n",
    "wine2.add(cx.Layer(\"input\", 11))\n",
    "wine2.add(cx.Layer(\"hidden1\", 9, activation=\"relu\"))\n",
    "wine2.add(cx.Layer(\"hidden2\", 7, activation=\"relu\"))\n",
    "wine2.add(cx.Layer(\"output\", 6, activation=\"sigmoid\"))\n",
    "wine2.connect()\n",
    "wine2.compile(error=\"mse\", optimizer=\"adam\")\n",
    "wine2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine2.picture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine2.propagate(input= [6.9, 0.605, 0.12, 10.7, 0.073, 40, 83, 0.9993, 3.45, 0.52, 9.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine2.dataset.load(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine2.reset()\n",
    "wine2.train(epochs=2000, accuracy=.75, tolerance=.2, report_rate=100, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Heck, we don't seem to be able to learn the signal we're after. \n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"ipynb.images/transmogrifier.png\" width=600 />\n",
    "</center>\n",
    "\n",
    "Can you fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting knowledge\n",
    "\n",
    "It is important, in doing your homework, that you understand what is going on. In the wines dataset, we have 11 \n",
    "independent variables (columns [0] to [10]), and one depedent variable (quality). A neural network graph is used,\n",
    "through the processes of `feedfoward` and `backpropagation`, to plot an ***11-dimensional surface*** (also called a \n",
    "[manifold](https://en.wikipedia.org/wiki/Manifold)) that is copletely triangulated. \n",
    "\n",
    "Remember our bunny?\n",
    "\n",
    "Here we draw a bunny point cloud in 3D that we present to a neural network graph to ***train on***. The $x$ and $y$ coordinates\n",
    "are the **independent variables**, and the $z$ coordinate is the dependent variable. We want to build a model *relating*\n",
    "$(x,y)$ to $z$. This is called classification. We are classifying $(x, y)$ tuples into a $z$ coordinate. So here is our \n",
    "\"*excel spreadsheet*\", which we can visualize as a point cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshplot as mp\n",
    "\n",
    "data = np.load('data/data.npz')\n",
    "v, f, n, fs = data[\"v\"], data[\"f\"], data[\"n\"], data[\"fs\"]\n",
    "v1, f1, v2, f2 = data[\"v1\"], data[\"f1\"], data[\"v2\"], data[\"f2\"]\n",
    "mp.plot(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are the \"***datapoints***\" the graph needs to learn. But instead of learning these datapoints, the graph ***learns***\n",
    "an entire triangulated manifold that looks like this, extrapolating information to fill-in the empty space in the bunny\n",
    "point cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.plot(v, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now when you have to ***predict*** a datapoint, say you have to predict some $z$ coordinate given only some $x$ and $y$ coordinates, \n",
    "you can just feedforward the $x$ and $y$ values through your neural network, intersecting the $(x,y)$ plane with the bunny manifold,\n",
    "yielding $z$!\n",
    "\n",
    "In other words, the ***input*** to your neural network graph is the bunny point cloud, and the result (by backpropagation, stored in the weights\n",
    "of the neural network) is the mesh-tiangulated bunny ***surface***, which allows you to do predictions on missing values inside \n",
    "$(x, y, z)$ triples.\n",
    "\n",
    "Artificial neural networks, just like your brain, are ***geometry engines***, experiencing reality as ***point-clouds*** of data,\n",
    "and building ***triangulated surface*** models, using the weights in the synapses of your brain or the nodes of your ANN.\n",
    "\n",
    ">**NOTE**: We did exactly the same thing in the beginning of the semester, when we built **pdf*** models out of samples of\n",
    "distributions we generated with a little bit of help from NumPy. The gaussian, Beta, Gamma functions ***interpolate*** the\n",
    "empty space between our sample dataponts, giving us a *continuous* curve that we can use to do predictions with.\n",
    "\n",
    "The only mystery is how backpropagation is done in your brain. As far as ANNs are concerned, we solves that problem in our\n",
    "previous notebook: using gradients.\n",
    "\n",
    "Now, our wines dataset is really 12-dimensional (11 independent variables and one label). So how can we exactly plot a \n",
    "12-dimensional manifold?\n",
    "\n",
    "## Principal component analysis\n",
    "[Principal component analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) essentially does something\n",
    "similar to finding eigenvectors of a linear map, expect it does this from an information-theoretic perspective rather\n",
    "than a geometric perspective. It finds the directions of an excel spreadsheeet where ***data varies the most*** and ranks\n",
    "them. It then returns the first one, the second one, as many as you want. \n",
    "\n",
    "But if you have a physical process underlying a dataset (the model, really), then most of the time the data varies the most\n",
    "on a smaller number of directions, and the other ones are mostly random noise. So, PCA is a dimensionality reduction\n",
    "technique that can be used to find lower-dimensional spaes that contain the ***essential information***.\n",
    "\n",
    ">**NOTE**: Ask me about my famous aquarium analogy!\n",
    "\n",
    "So let's do a PCA on our 11-dimensional data, and plot the 3 principal components. I call this our \"**bunny graph**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#wines.drop(['P1', 'P2', 'P3', 'P4'], axis=1, inplace=True)\n",
    "#wines.drop(columns=['P1', 'P2', 'P3', 'P4'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "features = wines.loc[1:,:10].values.astype(float)\n",
    "pca = PCA(n_components = 3)\n",
    "pca.fit(features)\n",
    "p = pca.transform(features)\n",
    "\n",
    "wines['P1'] = np.zeros(len(wines))\n",
    "wines['P1'][0] = \"First principal component\"\n",
    "wines['P1'][1:] = p[:,0]\n",
    "\n",
    "wines['P2'] = np.zeros(len(wines))\n",
    "wines['P2'][0] = \"Second principal component\"\n",
    "wines['P2'][1:] = p[:,1]\n",
    "\n",
    "wines['P3'] = np.zeros(len(wines))\n",
    "wines['P3'][0] = \"Third principal component\"\n",
    "wines['P3'][1:] = p[:,2]\n",
    "\n",
    "wines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = set(wines[[11]].values.flatten()[1:])\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get rid of the first row in `wines`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines2 = wines[1:]\n",
    "wines2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the `quality` column from a string over to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines2[11] = wines2[11].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, here are the better wines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines2[wines2[11] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wines2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7ece4e9902e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwines2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwines2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'P1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwines2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwines2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'P1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wines2' is not defined"
     ]
    }
   ],
   "source": [
    "len(wines2[wines2[11] <= 5]['P1'].values), len(wines2[wines2[11] > 5]['P1'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a pairs plot of the first two principal components and see if there is a correlation between them and quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "colors = [(0,.8,1),(1,.3,.2),(0,.7, .1),(.9,0,.1),(1,1,.1),(.1,.5, .9)]\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.xlabel('P1', fontsize = 15)\n",
    "plt.ylabel('P2', fontsize = 15)\n",
    "plt.title('2 component PCA', fontsize = 20)\n",
    "i = 3\n",
    "for cl, color in zip(classes,colors):\n",
    "    P1 = wines2[wines2[11] == i]['P1'].values\n",
    "    P2 = wines2[wines2[11] == i]['P2'].values\n",
    "    plt.scatter(P2, P1, c = color, s = 50)\n",
    "    i += 1\n",
    "plt.legend(classes)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wines of different quality are really tightly mixed into the same space, so it does not appear like a PCA deomposition\n",
    "would be of big help.\n",
    "\n",
    "Either way, it gives us an idea of the \"*shape*\" of the manifold we are about to train on, so I want to plot the manifold's\n",
    "point cloud for you.\n",
    "\n",
    "These are the three first principal components of our middle quality wines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wines2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f3f2c1918143>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwines2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwines2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'P1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwines2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwines2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'P2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mp3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwines2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwines2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'P3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wines2' is not defined"
     ]
    }
   ],
   "source": [
    "p1 = wines2[wines2[11] == 6]['P1'].values\n",
    "p2 = wines2[wines2[11] == 6]['P2'].values\n",
    "p3 = wines2[wines2[11] == 6]['P3'].values\n",
    "\n",
    "p1[0], p2[0], p3[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the point cloud. We will divide by 10 to shrink distances so that I can actually see a shape, otherwise the\n",
    "points may be too spread out apart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.34300628, -0.19511222,  0.26340395],\n",
       "       [ 0.95507043, -0.10065132, -0.04922433],\n",
       "       [ 1.60720258,  0.98011838,  0.0665192 ],\n",
       "       ...,\n",
       "       [ 0.94899841,  2.16275246, -0.19865579],\n",
       "       [-0.34313535,  1.42712435, -0.17507193],\n",
       "       [-0.38743766,  0.31263475, -0.18741493]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = []\n",
    "for i in range(0, len(p1)):\n",
    "    V.append([ p1[i]/10., p2[i]/10., p3[i]/10. ])\n",
    "W = np.array(V)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dec16eaca9944b5926adf6a02e5bcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(4.0424163…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mp.plot(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are *all* wines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = wines2['P1'].values\n",
    "p2 = wines2['P2'].values\n",
    "p3 = wines2['P3'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.14067320700021"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = []\n",
    "for i in range(0, len(p1)):\n",
    "    V.append([ p1[i]/10., p2[i]/10., p3[i]/10. ])\n",
    "W = np.array(V)\n",
    "np.max(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf18343508c44bb882707ab10edf339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(9.9535977…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mp.plot(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I'm seeing is a kind of \"*corner*\" structure.\n",
    "\n",
    "So what our ANN will do is to join that data with the label, and create a \"*bunny surface*\" using backpropagation.\n",
    "\n",
    ">**RECAP**: ANNs, just like your brain, are bayesian geometry engines, encoding information in mesh geometries that \n",
    "interpolate your point-cloud experiences. When you \"*train*\" (backpropagate) an ANN, you are building mesh-triangulated \n",
    "surfaces. When you *predict* (or think, or feedforward), you are computing intersections between your models and\n",
    "evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogy with real neural networks\n",
    "\n",
    "The human nervous system is composed of more than 100 billion cells known as neurons, maybe closer to 200 billion as we \n",
    "are born (and then neurons die when we are babies). Do you know how many stars are in a galaxy? How many galaxies in the \n",
    "universe? A neuron is a cell in the nervous system whose function it is to receive and transmit information. Neurons are \n",
    "made up of three major parts:\n",
    "\n",
    "* the cell body, or **soma**, which contains the nucleus of the cell and keeps the cell alive\n",
    "* a branching treelike fiber known as the **dendrite**, which collects information from other cells and sends the information to the soma\n",
    "* a long, segmented fiber known as the **axon**, which transmits information away from the cell body toward other neurons or to the muscles and glands\n",
    "\n",
    "<img src=\"https://c4.staticflickr.com/3/2656/4253587827_9723c3ffd3_z.jpg\" />\n",
    "\n",
    "*Photo courtesy of GE Healthcare, http://www.flickr.com/photos/gehealthcare/4253587827/ *\n",
    "\n",
    "<img src=\"https://askabiologist.asu.edu/sites/default/files/resources/articles/neuron_anatomy.jpg\"/>\n",
    "\n",
    "Some neurons have thousands of connections (dendrites), and these dendrites may themselves be branched to allow the cell \n",
    "to receive information from thousands of other cells. So a human brain has an order of a hundred trillion ($10^{14}$) \n",
    "connections.\n",
    "\n",
    "The axons are also specialized; some, such as those that send messages from the spinal cord to the muscles in the hands \n",
    "or feet, may be very long---even up to several feet in length. To improve the speed of their communication, and to keep \n",
    "their electrical charges from shorting out with other neurons, axons are often surrounded by a **myelin sheath**.\n",
    "\n",
    "The myelin sheath is a layer of fatty tissue surrounding the axon of a neuron that both acts as an insulator and allows \n",
    "faster transmission of the electrical signal. Axons branch out toward their ends, and at the tip of each branch is a \n",
    "*terminal button*.\n",
    "\n",
    "The actual working of neurons involves many aspects (including chemical, electrical, physical, timings). We abstract all \n",
    "of this away into three numbers:\n",
    "\n",
    "* **activation** - a value representing the excitement of a neuron\n",
    "* **default bias** - a value representing a default or bias (sometimes called a threshold)\n",
    "* **weight** - a value representing a connection to another neuron\n",
    "\n",
    "In addition, there is a **transfer function** that takes all of the incoming activations times their associated weights \n",
    "plus the bias, and squashes the resulting sum. This limits the activations from growing too big or too small.\n",
    "\n",
    "Time is handled in discrete steps. Real cells, of course, fire in non-discrete intervals. Consider the trigeminal ganglion \n",
    "cell: this is about 2 seconds of activity that was recorded from a rat ganglion cell after a single whisker (vibrissa) was \n",
    "moved and held in position. Listen for the rapid steady burst of action potentials. This neuron was firing about 100 \n",
    "action potentials every second. The picture below is the actual recording of a portion of what you are hearing...each \n",
    "action potential in this record is separated by about 10 milliseconds. There are 21 action potentials displayed in this \n",
    "picture of the recording.\n",
    "\n",
    "<img src=\"https://faculty.washington.edu/chudler/gif/spikes2.gif\" />\n",
    "\n",
    "This is what your brain sounds like on the inside. Imagine 100 billion cells doing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "rate must be specified when data is a numpy array or list of audio samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-079b7843c597>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/sndhair.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\lib\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rate must be specified when data is a numpy array or list of audio samples.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: rate must be specified when data is a numpy array or list of audio samples."
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(\"data/sndhair.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Hinton, G. (1992) [How Neural Networks Learn From Experience](https://www.academia.edu/631731/How_neural_networks_learn_from_experience). Scientific American. September, 1992."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
